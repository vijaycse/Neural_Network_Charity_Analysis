{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable 1: Preprocessing the Data for a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"resources/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "df_clean = application_df.drop(['EIN','NAME'], axis=1)  # axis=1 means drop the columns\n",
    "df_clean.head()\n",
    "df_original = df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "df_clean.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "df_clean['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the value counts of APPLICATION_TYPE\n",
    "df_clean['APPLICATION_TYPE'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "T9         156\n",
       "T13         66\n",
       "Other       54\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace if counts are less than 10\n",
    "replace_application_indicator = df_clean['APPLICATION_TYPE'].value_counts() < 50\n",
    "# switch the index with values \n",
    "replaced_application = pd.Series(replace_application_indicator.index.values, index=replace_application_indicator )\n",
    "# select only values that are less than 10 (aka true values)\n",
    "replaced_application = replaced_application[replaced_application.index.values == True]\n",
    "#print(replaced_application)\n",
    "# Replace in dataframe\n",
    "for app in replaced_application:\n",
    "    df_clean.APPLICATION_TYPE = df_clean.APPLICATION_TYPE.replace(app,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "df_clean.APPLICATION_TYPE.value_counts()\n",
    "#print(application_df['APPLICATION_TYPE']!='Other')\n",
    "#application_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "         ...  \n",
       "C4120        1\n",
       "C8210        1\n",
       "C2561        1\n",
       "C4500        1\n",
       "C2150        1\n",
       "Name: CLASSIFICATION, Length: 71, dtype: int64"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "df_clean['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgB0lEQVR4nO3dfZRc9X3f8fdnZ0azEkZCQosstFIlg8ARGAujKMSJbRyZILvF4B7ciLaBJDQKFCdxkubYNG3spodz7DQJKWnBJYYAfgATEwdiQ2IKaey6PHixhSSewgowWlCk5Vk8aNHufvvH/c3u3dnZXWl29sn38zpnzt793vu7853RaL/z+/3ugyICMzMzgLaZTsDMzGYPFwUzMxviomBmZkNcFMzMbIiLgpmZDSnPdALNWrp0aaxevXqm0zAzm1MefPDB5yOiY6z1c7YorF69mq6urplOw8xsTpH0o/HWe/jIzMyGuCiYmdkQFwUzMxsyYVGQdJ2kfZJ25mJfk7QtPZ6WtC3FV0t6M7fuC7k2p0naIalb0pWSlOLVtL9uSfdLWt36l2lmZofiUHoK1wOb84GI+IWIWB8R64Fbgb/Krd5VWxcRF+fiVwNbgbXpUdvnRcBLEXE8cAXw+WZeiJmZTd6ERSEivgO82Ghd+rb/r4CbxtuHpOXAwoi4N7Ir8N0InJtWnwPckJa/Dmyq9SLMzGx6TXZO4X3A3oh4IhdbI+mHkv5B0vtSbAXQk9umJ8Vq63YDREQ/8ApwdKMnk7RVUpekrt7e3kmmbmZm9SZbFM5nZC9hD7AqIk4Ffhv4qqSFQKNv/rVrdo+3bmQw4pqI2BARGzo6xjz3Ylzff/pF/ujvHqd/YLCp9mZmP86aLgqSysC/BL5Wi0VEX0S8kJYfBHYBJ5D1DDpzzTuB59JyD7Ayt89FjDFc1QrbnnmZ//H33Rzod1EwM6s3mZ7Ch4DHImJoWEhSh6RSWn4H2YTykxGxB9gv6fQ0X3ABcFtqdjtwYVo+D7gnpvDOP9VK9pL7Dg5M1VOYmc1Zh3JI6k3AvcCJknokXZRWbWH0BPP7ge2SHiKbNL44Imrf+i8Bvgh0k/Ug7kzxa4GjJXWTDTl9ehKvZ0Lt5RKAewpmZg1MeO2jiDh/jPgvNYjdSnaIaqPtu4CTG8QPAB+fKI9WqfUUDrinYGY2SuHOaK6mnkLfQfcUzMzqFa4otNd6Cv3uKZiZ1StgUUhzCh4+MjMbpXBFoVpORx95otnMbJTCFYVaT8GHpJqZjVbYonDAE81mZqMUrijUho88p2BmNlrhisLQ8JHnFMzMRilgUXBPwcxsLIUrCrWT1zynYGY2WuGKQqlNVEqizyevmZmNUriiANlF8dxTMDMbrZBFoVpp82UuzMwaKGZRKJd8QTwzswYKWRTa3VMwM2uokEUh6ym4KJiZ1StkUWivtPnkNTOzBgpaFEo+ec3MrIFCFoVquc2HpJqZNVDIotBeKfnkNTOzBiYsCpKuk7RP0s5c7LOSnpW0LT0+klt3maRuSY9LOisXP03SjrTuSklK8aqkr6X4/ZJWt/g1jpINH7mnYGZW71B6CtcDmxvEr4iI9elxB4CkdcAW4KTU5ipJpbT91cBWYG161PZ5EfBSRBwPXAF8vsnXcsiy4SP3FMzM6k1YFCLiO8CLh7i/c4CbI6IvIp4CuoGNkpYDCyPi3ogI4Ebg3FybG9Ly14FNtV7EVMmGj9xTMDOrN5k5hU9I2p6Glxan2Apgd26bnhRbkZbr4yPaREQ/8ApwdKMnlLRVUpekrt7e3qYTr1bcUzAza6TZonA1cBywHtgD/HGKN/qGH+PEx2szOhhxTURsiIgNHR0dh5VwXrWc9RSyTouZmdU0VRQiYm9EDETEIPDnwMa0qgdYmdu0E3guxTsbxEe0kVQGFnHow1VNqd1ox0NIZmYjNVUU0hxBzceA2pFJtwNb0hFFa8gmlB+IiD3Afkmnp/mCC4Dbcm0uTMvnAffEFH+Fb0832vFF8czMRipPtIGkm4AzgKWSeoDPAGdIWk82zPM08GsAEfGwpFuAR4B+4NKIqA3eX0J2JNN84M70ALgW+JKkbrIewpYWvK5xVWu35OwfYBGVqX46M7M5Y8KiEBHnNwhfO872lwOXN4h3ASc3iB8APj5RHq3knoKZWWOFPaMZ8OWzzczqFLIoVMtp+MiHpZqZjVDIolDrKfjoIzOzkQpaFNxTMDNrpJBFoZommn1RPDOzkQpZFIZPXnNPwcwsr6BFwT0FM7NGClkUfPSRmVljxSwKPvrIzKyhQhYFH31kZtZYIYvCvFIbEvS5KJiZjVDIoiCJarnNw0dmZnUKWRQgOwLJw0dmZiMVtihUy20+JNXMrE5hi0J7peST18zM6hS3KJRL7imYmdUpbFGoVtp8PwUzszqFLQrt5ZLvvGZmVqewRcE9BTOz0SYsCpKuk7RP0s5c7L9JekzSdknfkHRUiq+W9KakbenxhVyb0yTtkNQt6UpJSvGqpK+l+P2SVrf+ZY5W9ZyCmdkoh9JTuB7YXBe7Czg5Ik4B/hG4LLduV0SsT4+Lc/Grga3A2vSo7fMi4KWIOB64Avj8Yb+KJrRX2nz0kZlZnQmLQkR8B3ixLvbtiOhPv94HdI63D0nLgYURcW9EBHAjcG5afQ5wQ1r+OrCp1ouYSu0VzymYmdVrxZzCrwB35n5fI+mHkv5B0vtSbAXQk9umJ8Vq63YDpELzCnB0oyeStFVSl6Su3t7eSSWdnbzmnoKZWd6kioKk3wP6ga+k0B5gVUScCvw28FVJC4FG3/yjtptx1o0MRlwTERsiYkNHR8dkUk8nr7mnYGaWV262oaQLgX8BbEpDQkREH9CXlh+UtAs4gaxnkB9i6gSeS8s9wEqgR1IZWETdcNVUaK+4p2BmVq+pnoKkzcCngI9GxBu5eIekUlp+B9mE8pMRsQfYL+n0NF9wAXBbanY7cGFaPg+4p1ZkplK1XKJ/MOgfcG/BzKxmwp6CpJuAM4ClknqAz5AdbVQF7kpzwvelI43eD/yBpH5gALg4Imrf+i8hO5JpPtkcRG0e4lrgS5K6yXoIW1ryyiZQu9FOX/8g5VJhT9cwMxthwqIQEec3CF87xra3AreOsa4LOLlB/ADw8YnyaLX2dEvOAwcHOKLa9CiamdmPlcJ+Ra6W0y05PdlsZjaksEWh1lPwLTnNzIYVtihUy7XhI/cUzMxqilsUKrXhI/cUzMxqClsU2su14SP3FMzMaopbFNxTMDMbpbBFoVr2RLOZWb3CFoX8yWtmZpYpcFEYPnnNzMwyhS0KQyeveaLZzGxIYYuCewpmZqMVtijUegqeUzAzG1bYolAutVFuk3sKZmY5hS0KkA0heU7BzGxYwYtCG30+ec3MbEihi0K17J6CmVlesYtCpc2XuTAzyyl0UWgvl3xBPDOznEIXharnFMzMRih0UWgvl3xIqplZzoRFQdJ1kvZJ2pmLLZF0l6Qn0s/FuXWXSeqW9Liks3Lx0yTtSOuulKQUr0r6WorfL2l1i1/jmLKjjzx8ZGZWcyg9heuBzXWxTwN3R8Ra4O70O5LWAVuAk1KbqySVUpurga3A2vSo7fMi4KWIOB64Avh8sy/mcFXdUzAzG2HCohAR3wFerAufA9yQlm8Azs3Fb46Ivoh4CugGNkpaDiyMiHsjIoAb69rU9vV1YFOtFzHV2ittPiTVzCyn2TmFZRGxByD9PCbFVwC7c9v1pNiKtFwfH9EmIvqBV4CjGz2ppK2SuiR19fb2Npn6sPZKyRPNZmY5rZ5obvQNP8aJj9dmdDDimojYEBEbOjo6mkxxWLXsnoKZWV6zRWFvGhIi/dyX4j3Aytx2ncBzKd7ZID6ijaQysIjRw1VTIrv2kXsKZmY1zRaF24EL0/KFwG25+JZ0RNEasgnlB9IQ035Jp6f5ggvq2tT2dR5wT5p3mHLVSom+/kGm6enMzGa98kQbSLoJOANYKqkH+AzwOeAWSRcBzwAfB4iIhyXdAjwC9AOXRkTtq/glZEcyzQfuTA+Aa4EvSeom6yFsackrOwT5eyrUbrpjZlZkExaFiDh/jFWbxtj+cuDyBvEu4OQG8QOkojLdaoWg76CLgpkZFP2M5kqtp+B5BTMzKHhRqJZr92n2EUhmZlDwolDrKfjy2WZmmWIXhfLwnIKZmRW8KFTdUzAzG6HQRaF2xJFPYDMzyxS7KHj4yMxshEIXBQ8fmZmNVOii0O5DUs3MRih2UfDJa2ZmIxS6KPjkNTOzkYpdFGpzCj76yMwMKHpRyF0l1czMCl4UJFEtt9HnnoKZGVDwogC++5qZWZ6LQqXNw0dmZknhi0K17J6CmVlN4YtCe6XNh6SamSUuCpWST14zM0uaLgqSTpS0Lfd4VdInJX1W0rO5+EdybS6T1C3pcUln5eKnSdqR1l0pSZN9YYeqWnZPwcyspumiEBGPR8T6iFgPnAa8AXwjrb6iti4i7gCQtA7YApwEbAauklRK218NbAXWpsfmZvM6XO2Vki+IZ2aWtGr4aBOwKyJ+NM425wA3R0RfRDwFdAMbJS0HFkbEvRERwI3AuS3Ka0LVcsmXzjYzS1pVFLYAN+V+/4Sk7ZKuk7Q4xVYAu3Pb9KTYirRcHx9F0lZJXZK6ent7W5J4tdLmnoKZWTLpoiBpHvBR4C9T6GrgOGA9sAf449qmDZrHOPHRwYhrImJDRGzo6OiYTNpD2t1TMDMb0oqewoeBH0TEXoCI2BsRAxExCPw5sDFt1wOszLXrBJ5L8c4G8WmRnbzmnoKZGbSmKJxPbugozRHUfAzYmZZvB7ZIqkpaQzah/EBE7AH2Szo9HXV0AXBbC/I6JNnJa+4pmJkBlCfTWNIC4Ezg13LhP5S0nmwI6Onauoh4WNItwCNAP3BpRNS+ol8CXA/MB+5Mj2mRnbzmnoKZGUyyKETEG8DRdbFfHGf7y4HLG8S7gJMnk0uz2isl+geD/oFByqXCn8tnZgVX+L+CvqeCmdmwwheF9krtlpweQjIzc1GouKdgZlZT+KJQLbunYGZWU/iiUOsp+LBUMzMXBappTsEnsJmZuSgMHX3knoKZmYvC8NFH7imYmbkotKeJZl8Uz8zMRYHq0CGp7imYmRW+KBwxL7vSx8tvHJzhTMzMZl7hi8KyhVVWHDWf7z7Rmpv2mJnNZYUvCpI4c90yvvvE87zxVv9Mp2NmNqMKXxQAzly3jL7+Qb77xPMznYqZ2YxyUQA2rlnCwvYydz2yd6ZTMTObUS4KQKXUxgffeQz3PLaPgcGGt4c2MysEF4XkzHXLePH1t/jBMy/NdCpmZjPGRSH5wAkdVEryEJKZFZqLQnJke4WfPm4pdz2ylwgPIZlZMbko5Jz5E8fw1POvs6v3tZlOxcxsRkyqKEh6WtIOSdskdaXYEkl3SXoi/Vyc2/4ySd2SHpd0Vi5+WtpPt6QrJWkyeTXrQ+uWAfBtDyGZWUG1oqfwwYhYHxEb0u+fBu6OiLXA3el3JK0DtgAnAZuBqySVUpurga3A2vTY3IK8DtvyRfN514pFnlcws8KaiuGjc4Ab0vINwLm5+M0R0RcRTwHdwEZJy4GFEXFvZIP5N+baTLsz1y1j2+6X2bf/wEylYGY2YyZbFAL4tqQHJW1NsWURsQcg/TwmxVcAu3Nte1JsRVquj48iaaukLkldvb1Tc62iM9ctIwLufnTflOzfzGw2m2xR+JmIeA/wYeBSSe8fZ9tG8wQxTnx0MOKaiNgQERs6OjoOP9tD8M63H0nn4vnc85iLgpkVz6SKQkQ8l37uA74BbAT2piEh0s/aX9ceYGWueSfwXIp3NojPCEm8a8Uidu3zEUhmVjxNFwVJR0g6srYM/DywE7gduDBtdiFwW1q+HdgiqSppDdmE8gNpiGm/pNPTUUcX5NrMiFVLFtDz0psM+pIXZlYw5Um0XQZ8Ix09Wga+GhF/K+n7wC2SLgKeAT4OEBEPS7oFeAToBy6NiNrtzi4BrgfmA3emx4zpXLKAtwYG2be/j7cvap/JVMzMplXTRSEingTe3SD+ArBpjDaXA5c3iHcBJzebS6utWrIAgGdefMNFwcwKxWc0N7By8XwAdr/4xgxnYmY2vVwUGlixeD5S1lMwMysSF4UGquUSb1/Yzu6XXBTMrFhcFMawcvECel58c6bTMDObVi4KY1i5ZIGHj8yscFwUxrByyXz27j/AgYMDE29sZvZjwkVhDKuWLCACnn3ZQ0hmVhwuCmNYmc5V8GGpZlYkLgpjWLk4FYWX3FMws+JwURjDMUdWmVduc0/BzArFRWEMbW2ic/F8FwUzKxQXhXGs8mGpZlYwLgrjWLl4gXsKZlYoLgrjWLlkPq8e6OeVNw7OdCpmZtPCRWEctUto+xpIZlYULgrj6FzscxXMrFhcFMax6ujhm+2YmRWBi8I4FrZXWDS/4uEjMysMF4UJZIel+qxmMyuGpouCpJWS/l7So5IelvSbKf5ZSc9K2pYeH8m1uUxSt6THJZ2Vi58maUdad6UkTe5ltc7KJfPp8fCRmRXEZHoK/cDvRMRPAKcDl0pal9ZdERHr0+MOgLRuC3ASsBm4SlIpbX81sBVYmx6bJ5FXS61cvICel95kcDBmOhUzsynXdFGIiD0R8YO0vB94FFgxTpNzgJsjoi8ingK6gY2SlgMLI+LeiAjgRuDcZvNqtZVLFvDWwCB79x+Y6VTMzKZcS+YUJK0GTgXuT6FPSNou6TpJi1NsBbA716wnxVak5fp4o+fZKqlLUldvb28rUp/Q8CW0Pa9gZj/+Jl0UJL0NuBX4ZES8SjYUdBywHtgD/HFt0wbNY5z46GDENRGxISI2dHR0TDb1Q1I7gc2HpZpZEUyqKEiqkBWEr0TEXwFExN6IGIiIQeDPgY1p8x5gZa55J/Bcinc2iM8Kxx7VjuQT2MysGCZz9JGAa4FHI+JPcvHluc0+BuxMy7cDWyRVJa0hm1B+ICL2APslnZ72eQFwW7N5tVq1XGL5wnYXBTMrhPIk2v4M8IvADknbUuw/AudLWk82BPQ08GsAEfGwpFuAR8iOXLo0IgZSu0uA64H5wJ3pMWt0LlngE9jMrBCaLgoR8X9pPB9wxzhtLgcubxDvAk5uNpeptnLxAr7X/fxMp2FmNuUm01MojFVLFnDrqwf49K3bWfq2Kh1HVlm2sMoZJx5De6U08Q7MzOYIF4VD8HPvPIa7Hv0n7n5sHy+81kftPLbf+tAJ/OaH1s5scmZmLeSicAje1bmIb/76+wAYGAxeeuMtLvnyg9z+0LP8xqbjmUVX5TAzmxRfEO8wldrE0rdVOffUFezqfZ1H9rw60ymZmbWMi0KTPnzyckpt4m8e2jPTqZiZtYyLQpOWHDGPnz1+KX/z0HNkl2wyM5v7XBQm4aPvPpZnX36TH+5+eaZTMTNrCReFSTjzpGXMK7dx+7ZZc1UOM7NJcVGYhIXtFT54Ygff2rGHAd9vwcx+DLgoTNLZ7z6W3v193P/UCzOdipnZpLkoTNKmdy5jwbySj0Iysx8LLgqTNH9eiTPXLePOnXt4q39wptMxM5sUF4UWOPuUY3n5jYO+aJ6ZzXkuCi3wvhOWsrC9zK0/6Jl4YzOzWcxFoQWq5RLnb1zFN7fv4Y4dnlsws7nLRaFFfufnT+TUVUfxu3/5EN37XpvpdMzMmuKi0CLzym1c9W/eQ3ulxMVffpDX+/pnOiUzs8PmotBCyxfN58/OP5Une1/jU7du9zWRzGzOcVFosfcev5T/cNaJfHP7Hv7ie0/PdDpmZofFN9mZApd84Dh++MzL/ME3H+HL9/2IjWuW8FPvWMLGNUez4qj5M52emdmYZk1RkLQZ+O9ACfhiRHxuhlNqmiT+9BfW89X7n+G+J1/gWzv2cPP3dwNwzJFVTuk8ilM6F3FK5yJWLVlAm4TE0M95pTbmlbNHpdRGuU2+u5uZTQvNhnFvSSXgH4EzgR7g+8D5EfHIWG02bNgQXV1d05Th5AwMBo//034eeOoFHup5he09L/Pk869zqG+9BJVSG/NKbVRKolou8bb2MkdUyxxZLXNEtcSCeWUWzCuxYF6J+fPKVMvZtpVSG+VSG9VSG9VKG+2VEvMrJarlNkptWREC0aasmInh4lR77nr5IlZq03ARK7VRKbeh1K4tNR4qeKP27UJnNt0kPRgRG8ZaP1t6ChuB7oh4EkDSzcA5wJhFYS4ptYl1xy5k3bELh2L7Dxxkx7OvsPfVA0RABAxGEAFvDQzyVv8gB/M/B4KDA9nym28N8Ppb/bzWN8Drff307u/jjYP9WbxvgDcPDszgq23OWPUhKzAjC0rtZ21dbTsm2MdYz1MrWLUCObzvWvtDK17D2zcueFJ65J7j0Paby6CFdTT/3trc8hub1nL2u4+dkn3PlqKwAtid+70H+Kn6jSRtBbYCrFq1anoymyJHtld473FLp2Tfg4PBWwOD9A8G/QODHBwI+voHOHBwkAMHB4aWByMYDIhUjIIYWaAa7Dvr3WTtBiMYGAz66gpYtq/h/WTthtvU9hMjdzr6uYa2i6Hta4VzcHA4v9o2DfcR+eXR2+TzDIZfX23TQ+3N1Z5/xOuqy2P4/R0r27HajZ1/s9LLHPN9s9lt0fzKlO17thSFRl9WRn1aI+Ia4BrIho+mOqm5qq1NtLeVZjoNM5uDZsshqT3AytzvnYBvZ2ZmNs1mS1H4PrBW0hpJ84AtwO0znJOZWeHMiuGjiOiX9Ang78gOSb0uIh6e4bTMzApnVhQFgIi4A7hjpvMwMyuy2TJ8ZGZms4CLgpmZDXFRMDOzIS4KZmY2ZFZc+6gZknqBHzXZfCnwfAvTmWpzKd+5lCvMrXznUq4wt/KdS7nC5PL9ZxHRMdbKOVsUJkNS13gXhJpt5lK+cylXmFv5zqVcYW7lO5dyhanN18NHZmY2xEXBzMyGFLUoXDPTCRymuZTvXMoV5la+cylXmFv5zqVcYQrzLeScgpmZNVbUnoKZmTXgomBmZkPmdFGQ9HZJN0vaJekRSXdIOkHS30p6WdI367ZfI+l+SU9I+lq6TDfKXCmpW9J2Se/Jtdks6fG07tMtznWjpHslPZye9xdy239X0rb0eE7SX09XruPke4KkP0z5PpryUNp+tr23430OvpKed6ek6yRVUvyclOM2SV2SfjbFT8z9W2yT9KqkT7Y43w9IejDt/2FJFx9CvnPmvc2t/0lJA5LOy8V+K73mnZJuktQ+TbleL+mp3L/r+hT/3VxsZ8p3SVo31f/Hxvub8In0vCFpaS5+hqRXcjn/fm7d4eeb3Ypx7j3I7tZ2L3BxLrYeeB+wCTgb+GZdm1uALWn5C8AlafkjwJ1pn6cD96d4CdgFvAOYBzwErGthrh8A1qbfjwX2AEc1aH8rcMF05HoI+X4vPVcpbXPGLH1vx/scfCS1E3BTLte3MTzPdgrwWIPnKwH/RHYCUKvf22ouj6eBYyfId868t7m87iG7GvJ5KbYCeAqYn/sc/dI05Xp9LY9x9ns2cM80/x9r+DcBOBVYnT4bS3Ptzqh/bZPJd9ZcOrsJHwQORsQXaoGI2FZblnRGfmNJAn4O+NcpdAPwWeBq4BzgxsjeyfskHSVpOdk/QHdEPJn2cXPa9pFW5pp+f07SPqADeDmX95Ep719OoanOdcx8Jf000E72ARNQAfbO5ve2/nOQ1t+RW/8A2Z3+iIjXcpsdQePbLW8CdkVEs2fTT/hZAKrkevFj5cscem+TXyf7gvOTdc3KwHxJB4EFNHfXxcPO9RCdT1bcADYyxf/H8hvU/02IiB+m5z3U52gq37k8fHQy8OBhbH802Rvbn37vIfuWQvq5O7dtbd1Y8ZbnKmkj2R/bXXWrPgbcHRGvTlOuY+YbEfcCf0/27WUP8HcR8Siz/L0dSxra+EXgb3Oxj0l6DPgW8CsNmm1h+I9EM8bMV9JKSdvJ3pfPR8Rzdevr850z762kFWSf5S/kt4uIZ4E/Ap4h+0y9EhHfnsZcL0/DNFdIquZXSFoAbCYrZDAN/8fqnn+svwmN/LSkhyTdKemkFGsq37lcFA5Xo/IaE6wbr03LpG93XwJ+OSIG61bnv6kwTk5Tnquk44GfIPv2twL4OUnvn+C5Z/S9ncBVwHci4rtDCUR8IyLeCZwL/Nf8xsrmST4K/OVUJBMRuyPiFOB44EJJyybIdy69t38KfCoiBvIbSVpM9u11DdlwyRGS/u005XgZ8E6ynssS4FN1688GvhcRL9bSbbCPKXlfJ/ibUO8HZMOZ7wb+DPjr2m4abDthvnO5KDwMnHYY2z8PHCWpNmTWyXA3tQdYmdu2tm6seMtylbSQ7Fvpf4qI++rWHU3WBfxWLjzVuY6X78eA+yLitTTUcifZWPasfG/HI+kzZN3y3260PiK+AxyXn9ADPgz8ICL2NpFnzYT5ph7Cw2Tj4ePlO5fe2w3AzZKeBs4DrpJ0LvAh4KmI6I2Ig8BfAe+djlwjYk9k+oC/IPu/llffK5yO/2Pj/k1oJCJerQ19puG7SvrcNpdvM5Mks+FBVgXvB341F/tJ4AMxxuQL2Te8/GTov0/L/5yRE3YPpHgZeJLsW0xtouakVuYK3A18cox2FwM31MWmNNcJ8v0M8L/Tc1VS7mfP1vd2nM/BvwP+H2lyMxc/nuGJ5vcAz9Z+T7Gbyb65TcnnluHJ1sXAPwLvmiDfOfPe1m1zPcMTzT9F9gdyQXq+G4Bfn6Zcl+fa/inwudy6RcCLwBG52HT8Hxv3b0La7mlGTjS/Pfe53Ug2FKdm8236wz0bHmTdzVvIxtweJquua4HvAr3Am2TV8qy0/TuAB4Busj9itaM9BPzPtJ8dwIbcc3wk/QfdBfxei3P9z8BBYFvusT7X5v8Amxt8mKY013HyPRH4X8CjZJNVf5Lbfra9t+N9DvrTtrX3/PdT/FOp/TayI0N+NvccC4AXgEVT9Ln9VWB7+o+7Hdia236sfOfMe1u3z+vJHfUD/BfgMWAn2ZBJdZpyvSe9bzuBLwNvy+3rl4CbGzzHVP8fG/NvAvAbKf9+sm/8X0zxT6T2DwH3Ae+dTL6+zIWZmQ2Zy3MKZmbWYi4KZmY2xEXBzMyGuCiYmdkQFwUzMxviomBmZkNcFMzMbMj/B1g3WcsbythOAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the value counts of CLASSIFICATION\n",
    "df_clean['CLASSIFICATION'].value_counts().plot(kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "Other      391\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace if counts are less than 10\n",
    "replace_class_indicator = df_clean['CLASSIFICATION'].value_counts() < 50\n",
    "# switch the index with values \n",
    "replace_class = pd.Series(replace_class_indicator.index.values, index=replace_class_indicator )\n",
    "# select only values that are less than 10 (aka true values)\n",
    "replace_class = replace_class[replace_class.index.values == True]\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in replace_class:\n",
    "    df_clean.CLASSIFICATION = df_clean.CLASSIFICATION.replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "df_clean.CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APPLICATION_TYPE',\n",
       " 'AFFILIATION',\n",
       " 'CLASSIFICATION',\n",
       " 'USE_CASE',\n",
       " 'ORGANIZATION',\n",
       " 'INCOME_AMT',\n",
       " 'SPECIAL_CONSIDERATIONS']"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable lists\n",
    "application_cat = df_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "application_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE          11\n",
       "AFFILIATION                6\n",
       "CLASSIFICATION            16\n",
       "USE_CASE                   5\n",
       "ORGANIZATION               4\n",
       "INCOME_AMT                 9\n",
       "SPECIAL_CONSIDERATIONS     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[application_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T13</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>APPLICATION_TYPE_T8</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  APPLICATION_TYPE_T13  \\\n",
       "0                     0.0                   1.0                   0.0   \n",
       "1                     0.0                   0.0                   0.0   \n",
       "2                     0.0                   0.0                   0.0   \n",
       "3                     0.0                   0.0                   0.0   \n",
       "4                     0.0                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "0                   0.0                  0.0                  0.0   \n",
       "1                   0.0                  1.0                  0.0   \n",
       "2                   0.0                  0.0                  0.0   \n",
       "3                   0.0                  1.0                  0.0   \n",
       "4                   0.0                  1.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  1.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T8  ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
       "0                  0.0  ...                0.0                     0.0   \n",
       "1                  0.0  ...                1.0                     0.0   \n",
       "2                  0.0  ...                0.0                     0.0   \n",
       "3                  0.0  ...                0.0                     1.0   \n",
       "4                  0.0  ...                0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
       "0                       0.0                 0.0               0.0   \n",
       "1                       0.0                 0.0               0.0   \n",
       "2                       0.0                 0.0               0.0   \n",
       "3                       0.0                 0.0               0.0   \n",
       "4                       1.0                 0.0               0.0   \n",
       "\n",
       "   INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \\\n",
       "0                     0.0              0.0                0.0   \n",
       "1                     0.0              0.0                0.0   \n",
       "2                     0.0              0.0                0.0   \n",
       "3                     0.0              0.0                0.0   \n",
       "4                     0.0              0.0                0.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       1.0                       0.0  \n",
       "1                       1.0                       0.0  \n",
       "2                       1.0                       0.0  \n",
       "3                       1.0                       0.0  \n",
       "4                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(df_clean[application_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(application_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-517-024d8c5d6c36>:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df_application.drop(application_cat, 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T13</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                     0.0   \n",
       "1       1   108590              1                     0.0   \n",
       "2       1     5000              0                     0.0   \n",
       "3       1     6692              1                     0.0   \n",
       "4       1   142590              1                     0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T13  APPLICATION_TYPE_T19  \\\n",
       "0                   1.0                   0.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  ...  \\\n",
       "0                  0.0                  0.0                  0.0  ...   \n",
       "1                  1.0                  0.0                  0.0  ...   \n",
       "2                  0.0                  0.0                  1.0  ...   \n",
       "3                  1.0                  0.0                  0.0  ...   \n",
       "4                  1.0                  0.0                  0.0  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "df_application = df_clean.merge(encode_df, left_index=True, right_index=True)\n",
    "df_application.drop(application_cat, 1, inplace=True)\n",
    "df_application.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df_application[\"IS_SUCCESSFUL\"].values\n",
    "X = df_application.drop([\"IS_SUCCESSFUL\"], axis=1)\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=50, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T13</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  \\\n",
       "0       1     5000                     0.0                   1.0   \n",
       "1       1   108590                     0.0                   0.0   \n",
       "2       1     5000                     0.0                   0.0   \n",
       "3       1     6692                     0.0                   0.0   \n",
       "4       1   142590                     0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T13  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                   0.0                   0.0                  0.0   \n",
       "1                   0.0                   0.0                  1.0   \n",
       "2                   0.0                   0.0                  0.0   \n",
       "3                   0.0                   0.0                  1.0   \n",
       "4                   0.0                   0.0                  1.0   \n",
       "\n",
       "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "0                  0.0                  0.0                  0.0  ...   \n",
       "1                  0.0                  0.0                  0.0  ...   \n",
       "2                  0.0                  1.0                  0.0  ...   \n",
       "3                  0.0                  0.0                  0.0  ...   \n",
       "4                  0.0                  0.0                  0.0  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st attempt to optimize: optimize the Model - Target Accuracy better than 72%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "82\n",
      "55\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_88 (Dense)            (None, 82)                4592      \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 55)                4565      \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 1)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,213\n",
      "Trainable params: 9,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "no_of_features = len(X_train_scaled[0])\n",
    "no_of_nodes_layer1 = int(no_of_features * 1.5)\n",
    "no_of_nodes_layer2 = int(no_of_features * 1)\n",
    "no_of_output_nodes = 1\n",
    "\n",
    "### print all the layers input\n",
    "print(no_of_features)\n",
    "print(no_of_nodes_layer1)\n",
    "print(no_of_nodes_layer2)\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=no_of_nodes_layer1, activation='relu', input_dim=no_of_features))\n",
    "\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=no_of_nodes_layer2, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=no_of_output_nodes, activation='sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"AlphabetSoupCharity_Optimization.h5\", verbose=1, save_weights_only=True, save_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "858/858 [==============================] - 1s 938us/step - loss: 0.5737 - accuracy: 0.7165\n",
      "Epoch 2/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5587 - accuracy: 0.7261\n",
      "Epoch 3/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5545 - accuracy: 0.7277\n",
      "Epoch 4/100\n",
      "858/858 [==============================] - 1s 934us/step - loss: 0.5523 - accuracy: 0.7281\n",
      "Epoch 5/100\n",
      "858/858 [==============================] - 1s 907us/step - loss: 0.5514 - accuracy: 0.7282\n",
      "Epoch 6/100\n",
      "858/858 [==============================] - 1s 921us/step - loss: 0.5497 - accuracy: 0.7311\n",
      "Epoch 7/100\n",
      "858/858 [==============================] - 1s 918us/step - loss: 0.5483 - accuracy: 0.7303\n",
      "Epoch 8/100\n",
      "858/858 [==============================] - 1s 911us/step - loss: 0.5476 - accuracy: 0.7312\n",
      "Epoch 9/100\n",
      "858/858 [==============================] - 1s 934us/step - loss: 0.5470 - accuracy: 0.7322\n",
      "Epoch 10/100\n",
      "858/858 [==============================] - 1s 911us/step - loss: 0.5462 - accuracy: 0.7327\n",
      "Epoch 11/100\n",
      "858/858 [==============================] - 1s 948us/step - loss: 0.5459 - accuracy: 0.7321\n",
      "Epoch 12/100\n",
      "858/858 [==============================] - 1s 897us/step - loss: 0.5449 - accuracy: 0.7334\n",
      "Epoch 13/100\n",
      "858/858 [==============================] - 1s 887us/step - loss: 0.5444 - accuracy: 0.7340\n",
      "Epoch 14/100\n",
      "858/858 [==============================] - 1s 886us/step - loss: 0.5434 - accuracy: 0.7342\n",
      "Epoch 15/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5432 - accuracy: 0.7353\n",
      "Epoch 16/100\n",
      "858/858 [==============================] - 1s 891us/step - loss: 0.5430 - accuracy: 0.7353\n",
      "Epoch 17/100\n",
      "858/858 [==============================] - 1s 865us/step - loss: 0.5424 - accuracy: 0.7349\n",
      "Epoch 18/100\n",
      "858/858 [==============================] - 1s 900us/step - loss: 0.5419 - accuracy: 0.7354\n",
      "Epoch 19/100\n",
      "858/858 [==============================] - 1s 865us/step - loss: 0.5421 - accuracy: 0.7352\n",
      "Epoch 20/100\n",
      "858/858 [==============================] - 1s 867us/step - loss: 0.5414 - accuracy: 0.7361\n",
      "Epoch 21/100\n",
      "858/858 [==============================] - 1s 911us/step - loss: 0.5410 - accuracy: 0.7349\n",
      "Epoch 22/100\n",
      "858/858 [==============================] - 1s 882us/step - loss: 0.5411 - accuracy: 0.7358\n",
      "Epoch 23/100\n",
      "858/858 [==============================] - 1s 928us/step - loss: 0.5405 - accuracy: 0.7370\n",
      "Epoch 24/100\n",
      "858/858 [==============================] - 1s 917us/step - loss: 0.5406 - accuracy: 0.7362\n",
      "Epoch 25/100\n",
      "858/858 [==============================] - 1s 889us/step - loss: 0.5398 - accuracy: 0.7365\n",
      "Epoch 26/100\n",
      "858/858 [==============================] - 1s 967us/step - loss: 0.5403 - accuracy: 0.7365\n",
      "Epoch 27/100\n",
      "858/858 [==============================] - 1s 909us/step - loss: 0.5395 - accuracy: 0.7364\n",
      "Epoch 28/100\n",
      "858/858 [==============================] - 1s 932us/step - loss: 0.5394 - accuracy: 0.7362\n",
      "Epoch 29/100\n",
      "858/858 [==============================] - 1s 924us/step - loss: 0.5390 - accuracy: 0.7377\n",
      "Epoch 30/100\n",
      "858/858 [==============================] - 1s 906us/step - loss: 0.5394 - accuracy: 0.7371\n",
      "Epoch 31/100\n",
      "858/858 [==============================] - 1s 929us/step - loss: 0.5389 - accuracy: 0.7372\n",
      "Epoch 32/100\n",
      "858/858 [==============================] - 1s 852us/step - loss: 0.5382 - accuracy: 0.7366\n",
      "Epoch 33/100\n",
      "858/858 [==============================] - 1s 891us/step - loss: 0.5382 - accuracy: 0.7373\n",
      "Epoch 34/100\n",
      "858/858 [==============================] - 1s 917us/step - loss: 0.5377 - accuracy: 0.7379\n",
      "Epoch 35/100\n",
      "858/858 [==============================] - 1s 843us/step - loss: 0.5379 - accuracy: 0.7376\n",
      "Epoch 36/100\n",
      "858/858 [==============================] - 1s 883us/step - loss: 0.5375 - accuracy: 0.7376\n",
      "Epoch 37/100\n",
      "858/858 [==============================] - 1s 877us/step - loss: 0.5378 - accuracy: 0.7373\n",
      "Epoch 38/100\n",
      "858/858 [==============================] - 1s 916us/step - loss: 0.5371 - accuracy: 0.7380\n",
      "Epoch 39/100\n",
      "858/858 [==============================] - 1s 937us/step - loss: 0.5372 - accuracy: 0.7388\n",
      "Epoch 40/100\n",
      "858/858 [==============================] - 1s 863us/step - loss: 0.5375 - accuracy: 0.7379\n",
      "Epoch 41/100\n",
      "858/858 [==============================] - 1s 928us/step - loss: 0.5369 - accuracy: 0.7380\n",
      "Epoch 42/100\n",
      "858/858 [==============================] - 1s 925us/step - loss: 0.5369 - accuracy: 0.7380\n",
      "Epoch 43/100\n",
      "858/858 [==============================] - 1s 927us/step - loss: 0.5368 - accuracy: 0.7368\n",
      "Epoch 44/100\n",
      "858/858 [==============================] - 1s 897us/step - loss: 0.5371 - accuracy: 0.7384\n",
      "Epoch 45/100\n",
      "858/858 [==============================] - 1s 887us/step - loss: 0.5366 - accuracy: 0.7397\n",
      "Epoch 46/100\n",
      "858/858 [==============================] - 1s 925us/step - loss: 0.5366 - accuracy: 0.7382\n",
      "Epoch 47/100\n",
      "858/858 [==============================] - 1s 872us/step - loss: 0.5365 - accuracy: 0.7379\n",
      "Epoch 48/100\n",
      "858/858 [==============================] - 1s 865us/step - loss: 0.5359 - accuracy: 0.7389\n",
      "Epoch 49/100\n",
      "858/858 [==============================] - 1s 908us/step - loss: 0.5359 - accuracy: 0.7384\n",
      "Epoch 50/100\n",
      "858/858 [==============================] - 1s 887us/step - loss: 0.5361 - accuracy: 0.7385\n",
      "Epoch 51/100\n",
      "858/858 [==============================] - 1s 923us/step - loss: 0.5358 - accuracy: 0.7390\n",
      "Epoch 52/100\n",
      "858/858 [==============================] - 1s 876us/step - loss: 0.5358 - accuracy: 0.7383\n",
      "Epoch 53/100\n",
      "858/858 [==============================] - 1s 875us/step - loss: 0.5359 - accuracy: 0.7378\n",
      "Epoch 54/100\n",
      "858/858 [==============================] - 1s 884us/step - loss: 0.5355 - accuracy: 0.7383\n",
      "Epoch 55/100\n",
      "858/858 [==============================] - 1s 923us/step - loss: 0.5353 - accuracy: 0.7383\n",
      "Epoch 56/100\n",
      "858/858 [==============================] - 1s 902us/step - loss: 0.5355 - accuracy: 0.7380\n",
      "Epoch 57/100\n",
      "858/858 [==============================] - 1s 899us/step - loss: 0.5352 - accuracy: 0.7394\n",
      "Epoch 58/100\n",
      "858/858 [==============================] - 1s 878us/step - loss: 0.5355 - accuracy: 0.7384\n",
      "Epoch 59/100\n",
      "858/858 [==============================] - 1s 847us/step - loss: 0.5351 - accuracy: 0.7382\n",
      "Epoch 60/100\n",
      "858/858 [==============================] - 1s 926us/step - loss: 0.5350 - accuracy: 0.7388\n",
      "Epoch 61/100\n",
      "858/858 [==============================] - 1s 942us/step - loss: 0.5347 - accuracy: 0.7387\n",
      "Epoch 62/100\n",
      "858/858 [==============================] - 1s 903us/step - loss: 0.5352 - accuracy: 0.7391\n",
      "Epoch 63/100\n",
      "858/858 [==============================] - 1s 891us/step - loss: 0.5347 - accuracy: 0.7384\n",
      "Epoch 64/100\n",
      "858/858 [==============================] - 1s 866us/step - loss: 0.5344 - accuracy: 0.7392\n",
      "Epoch 65/100\n",
      "858/858 [==============================] - 1s 928us/step - loss: 0.5344 - accuracy: 0.7388\n",
      "Epoch 66/100\n",
      "858/858 [==============================] - 1s 951us/step - loss: 0.5342 - accuracy: 0.7403\n",
      "Epoch 67/100\n",
      "858/858 [==============================] - 1s 867us/step - loss: 0.5342 - accuracy: 0.7383\n",
      "Epoch 68/100\n",
      "858/858 [==============================] - 1s 940us/step - loss: 0.5346 - accuracy: 0.7387\n",
      "Epoch 69/100\n",
      "858/858 [==============================] - 1s 943us/step - loss: 0.5346 - accuracy: 0.7389\n",
      "Epoch 70/100\n",
      "858/858 [==============================] - 1s 843us/step - loss: 0.5345 - accuracy: 0.7387\n",
      "Epoch 71/100\n",
      "858/858 [==============================] - 1s 906us/step - loss: 0.5342 - accuracy: 0.7391\n",
      "Epoch 72/100\n",
      "858/858 [==============================] - 1s 920us/step - loss: 0.5347 - accuracy: 0.7383\n",
      "Epoch 73/100\n",
      "858/858 [==============================] - 1s 858us/step - loss: 0.5343 - accuracy: 0.7382\n",
      "Epoch 74/100\n",
      "858/858 [==============================] - 1s 909us/step - loss: 0.5343 - accuracy: 0.7395\n",
      "Epoch 75/100\n",
      "858/858 [==============================] - 1s 888us/step - loss: 0.5337 - accuracy: 0.7391\n",
      "Epoch 76/100\n",
      "858/858 [==============================] - 1s 955us/step - loss: 0.5341 - accuracy: 0.7393\n",
      "Epoch 77/100\n",
      "858/858 [==============================] - 1s 903us/step - loss: 0.5338 - accuracy: 0.7398\n",
      "Epoch 78/100\n",
      "858/858 [==============================] - 1s 852us/step - loss: 0.5336 - accuracy: 0.7385\n",
      "Epoch 79/100\n",
      "858/858 [==============================] - 1s 884us/step - loss: 0.5336 - accuracy: 0.7397\n",
      "Epoch 80/100\n",
      "858/858 [==============================] - 1s 935us/step - loss: 0.5337 - accuracy: 0.7393\n",
      "Epoch 81/100\n",
      "858/858 [==============================] - 1s 910us/step - loss: 0.5335 - accuracy: 0.7392\n",
      "Epoch 82/100\n",
      "858/858 [==============================] - 1s 895us/step - loss: 0.5331 - accuracy: 0.7393\n",
      "Epoch 83/100\n",
      "858/858 [==============================] - 1s 829us/step - loss: 0.5334 - accuracy: 0.7392\n",
      "Epoch 84/100\n",
      "858/858 [==============================] - 1s 917us/step - loss: 0.5337 - accuracy: 0.7388\n",
      "Epoch 85/100\n",
      "858/858 [==============================] - 1s 947us/step - loss: 0.5335 - accuracy: 0.7403\n",
      "Epoch 86/100\n",
      "858/858 [==============================] - 1s 850us/step - loss: 0.5329 - accuracy: 0.7393\n",
      "Epoch 87/100\n",
      "858/858 [==============================] - 1s 879us/step - loss: 0.5329 - accuracy: 0.7399\n",
      "Epoch 88/100\n",
      "858/858 [==============================] - 1s 887us/step - loss: 0.5328 - accuracy: 0.7395\n",
      "Epoch 89/100\n",
      "858/858 [==============================] - 1s 923us/step - loss: 0.5329 - accuracy: 0.7392\n",
      "Epoch 90/100\n",
      "858/858 [==============================] - 1s 893us/step - loss: 0.5329 - accuracy: 0.7391\n",
      "Epoch 91/100\n",
      "858/858 [==============================] - 1s 892us/step - loss: 0.5332 - accuracy: 0.7402\n",
      "Epoch 92/100\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5335 - accuracy: 0.7396\n",
      "Epoch 93/100\n",
      "858/858 [==============================] - 1s 927us/step - loss: 0.5327 - accuracy: 0.7391\n",
      "Epoch 94/100\n",
      "858/858 [==============================] - 1s 879us/step - loss: 0.5330 - accuracy: 0.7402\n",
      "Epoch 95/100\n",
      "858/858 [==============================] - 1s 885us/step - loss: 0.5328 - accuracy: 0.7398\n",
      "Epoch 96/100\n",
      "858/858 [==============================] - 1s 895us/step - loss: 0.5327 - accuracy: 0.7397\n",
      "Epoch 97/100\n",
      "858/858 [==============================] - 1s 895us/step - loss: 0.5328 - accuracy: 0.7392\n",
      "Epoch 98/100\n",
      "858/858 [==============================] - 1s 865us/step - loss: 0.5329 - accuracy: 0.7392\n",
      "Epoch 99/100\n",
      "858/858 [==============================] - 1s 914us/step - loss: 0.5327 - accuracy: 0.7397\n",
      "Epoch 100/100\n",
      "858/858 [==============================] - 1s 901us/step - loss: 0.5326 - accuracy: 0.7394\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model = nn.fit(X_train_scaled, y_train, epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 0s - loss: 0.5423 - accuracy: 0.7405 - 193ms/epoch - 897us/step\n",
      "Loss: 0.5422736406326294, Accuracy: 0.7405247688293457\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2nd attempt ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APPLICATION_TYPE',\n",
       " 'AFFILIATION',\n",
       " 'CLASSIFICATION',\n",
       " 'USE_CASE',\n",
       " 'ORGANIZATION',\n",
       " 'STATUS',\n",
       " 'INCOME_AMT',\n",
       " 'SPECIAL_CONSIDERATIONS',\n",
       " 'ASK_AMT',\n",
       " 'IS_SUCCESSFUL']"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable lists\n",
    "df_orig_iter2 = df_original.copy()\n",
    "application_cat_iter2 = df_orig_iter2.columns.tolist()\n",
    "application_cat_iter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T12</th>\n",
       "      <th>APPLICATION_TYPE_T13</th>\n",
       "      <th>APPLICATION_TYPE_T14</th>\n",
       "      <th>APPLICATION_TYPE_T15</th>\n",
       "      <th>APPLICATION_TYPE_T17</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T2</th>\n",
       "      <th>APPLICATION_TYPE_T25</th>\n",
       "      <th>APPLICATION_TYPE_T29</th>\n",
       "      <th>...</th>\n",
       "      <th>ASK_AMT_1893400128</th>\n",
       "      <th>ASK_AMT_2264109450</th>\n",
       "      <th>ASK_AMT_2310256039</th>\n",
       "      <th>ASK_AMT_3391919220</th>\n",
       "      <th>ASK_AMT_4653011914</th>\n",
       "      <th>ASK_AMT_5591584994</th>\n",
       "      <th>ASK_AMT_8556638692</th>\n",
       "      <th>ASK_AMT_8597806340</th>\n",
       "      <th>IS_SUCCESSFUL_0</th>\n",
       "      <th>IS_SUCCESSFUL_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8865 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T12  APPLICATION_TYPE_T13  \\\n",
       "0                   1.0                   0.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T14  APPLICATION_TYPE_T15  APPLICATION_TYPE_T17  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T19  APPLICATION_TYPE_T2  APPLICATION_TYPE_T25  \\\n",
       "0                   0.0                  0.0                   0.0   \n",
       "1                   0.0                  0.0                   0.0   \n",
       "2                   0.0                  0.0                   0.0   \n",
       "3                   0.0                  0.0                   0.0   \n",
       "4                   0.0                  0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T29  ...  ASK_AMT_1893400128  ASK_AMT_2264109450  \\\n",
       "0                   0.0  ...                 0.0                 0.0   \n",
       "1                   0.0  ...                 0.0                 0.0   \n",
       "2                   0.0  ...                 0.0                 0.0   \n",
       "3                   0.0  ...                 0.0                 0.0   \n",
       "4                   0.0  ...                 0.0                 0.0   \n",
       "\n",
       "   ASK_AMT_2310256039  ASK_AMT_3391919220  ASK_AMT_4653011914  \\\n",
       "0                 0.0                 0.0                 0.0   \n",
       "1                 0.0                 0.0                 0.0   \n",
       "2                 0.0                 0.0                 0.0   \n",
       "3                 0.0                 0.0                 0.0   \n",
       "4                 0.0                 0.0                 0.0   \n",
       "\n",
       "   ASK_AMT_5591584994  ASK_AMT_8556638692  ASK_AMT_8597806340  \\\n",
       "0                 0.0                 0.0                 0.0   \n",
       "1                 0.0                 0.0                 0.0   \n",
       "2                 0.0                 0.0                 0.0   \n",
       "3                 0.0                 0.0                 0.0   \n",
       "4                 0.0                 0.0                 0.0   \n",
       "\n",
       "   IS_SUCCESSFUL_0  IS_SUCCESSFUL_1  \n",
       "0              0.0              1.0  \n",
       "1              0.0              1.0  \n",
       "2              1.0              0.0  \n",
       "3              0.0              1.0  \n",
       "4              0.0              1.0  \n",
       "\n",
       "[5 rows x 8865 columns]"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(df_orig_iter2[application_cat_iter2]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(application_cat_iter2)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig_iter2[application_cat_iter2].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-529-dab63d8ddcde>:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df_application_iter2.drop(application_cat_iter2, 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['APPLICATION_TYPE',\n",
       " 'AFFILIATION',\n",
       " 'CLASSIFICATION',\n",
       " 'USE_CASE',\n",
       " 'ORGANIZATION',\n",
       " 'INCOME_AMT',\n",
       " 'SPECIAL_CONSIDERATIONS']"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "df_application_iter2 = df_orig_iter2.merge(encode_df, left_index=True, right_index=True)\n",
    "df_application_iter2.drop(application_cat_iter2, 1, inplace=True)\n",
    "#df_application_iter1.head()\n",
    "application_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['APPLICATION_TYPE_T10', 'APPLICATION_TYPE_T12', 'APPLICATION_TYPE_T13',\n",
       "       'APPLICATION_TYPE_T14', 'APPLICATION_TYPE_T15', 'APPLICATION_TYPE_T17',\n",
       "       'APPLICATION_TYPE_T19', 'APPLICATION_TYPE_T2', 'APPLICATION_TYPE_T25',\n",
       "       'APPLICATION_TYPE_T29',\n",
       "       ...\n",
       "       'ASK_AMT_1893400128', 'ASK_AMT_2264109450', 'ASK_AMT_2310256039',\n",
       "       'ASK_AMT_3391919220', 'ASK_AMT_4653011914', 'ASK_AMT_5591584994',\n",
       "       'ASK_AMT_8556638692', 'ASK_AMT_8597806340', 'IS_SUCCESSFUL_0',\n",
       "       'IS_SUCCESSFUL_1'],\n",
       "      dtype='object', length=8865)"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_application_iter2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'IS_SUCCESSFUL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'IS_SUCCESSFUL'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-531-dfa336eaeb85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Split our preprocessed data into our features and target arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_application_iter2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"IS_SUCCESSFUL\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_application_iter2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"IS_SUCCESSFUL\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Split the preprocessed data into a training and testing dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'IS_SUCCESSFUL'"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y2 = df_application_iter2[\"IS_SUCCESSFUL\"].values\n",
    "X2 = df_application_iter2.drop([\"IS_SUCCESSFUL\"], axis=1)\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X2, y2, random_state=50, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler_2 = scaler.fit(X_train_2)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled_2 = X_scaler_2.transform(X_train_2)\n",
    "X_test_scaled_2 = X_scaler_2.transform(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "no_of_features = len(X_train_scaled_2[0])\n",
    "no_of_nodes_layer1 = int(no_of_features * 0.70)\n",
    "no_of_nodes_layer2 = int(no_of_features * 0.50)\n",
    "no_of_output_nodes = 1\n",
    "\n",
    "### print all the layers input\n",
    "print(no_of_features)\n",
    "print(no_of_nodes_layer1)\n",
    "print(no_of_nodes_layer2)\n",
    "\n",
    "nn2 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=no_of_nodes_layer1, activation='tanh', input_dim=no_of_features))\n",
    "\n",
    "\n",
    "# Second hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=no_of_nodes_layer2, activation='tanh'))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn2.add(tf.keras.layers.Dense(units=no_of_output_nodes, activation='sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"AlphabetSoupCharity_Optimization.h5\", verbose=1, save_weights_only=True, save_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = nn2.fit(X_train_scaled_2, y_train_2, epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn2.evaluate(X_test_scaled_2,y_test_2,verbose=1)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####3rd attempt ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd attempt to optimize: optimize the Model - Target Accuracy better than 74%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3                 27037\n",
       "Thousands-Group     4996\n",
       "5Hundreds-Group     1990\n",
       "T9                   156\n",
       "T13                   66\n",
       "Other                 54\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#copy the dataframe\n",
    "df_orig_iter3 = df_clean.copy()\n",
    "\n",
    "# Determine which values to replace if counts are less than 10\n",
    "replace_application_indicator_1 = ((df_orig_iter3['APPLICATION_TYPE'].value_counts() > 1000) & (df_orig_iter3['APPLICATION_TYPE'].value_counts() < 5000))\n",
    "replaced_application_1 = pd.Series(replace_application_indicator_1.index.values, index=replace_application_indicator_1 )\n",
    "# select only values that are less than 10 (aka true values)\n",
    "replaced_application_1 = replaced_application_1[replaced_application_1.index.values == True]\n",
    "#print(replaced_application)\n",
    "# Replace in dataframe\n",
    "for app in replaced_application_1:\n",
    "    df_orig_iter3.APPLICATION_TYPE = df_orig_iter3.APPLICATION_TYPE.replace(app,\"Thousands-Group\")\n",
    "\n",
    "\n",
    "# Determine which values to replace if counts are less than 10\n",
    "replace_application_indicator_2 = ((df_orig_iter3['APPLICATION_TYPE'].value_counts() > 500) & (df_orig_iter3['APPLICATION_TYPE'].value_counts() < 1000))\n",
    "replaced_application_2 = pd.Series(replace_application_indicator_2.index.values, index=replace_application_indicator_2 )\n",
    "# select only values that are less than 10 (aka true values)\n",
    "replaced_application_2 = replaced_application_2[replaced_application_2.index.values == True]\n",
    "#print(replaced_application)\n",
    "# Replace in dataframe\n",
    "for app in replaced_application_2:\n",
    "    df_orig_iter3.APPLICATION_TYPE = df_orig_iter3.APPLICATION_TYPE.replace(app,\"5Hundreds-Group\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "df_orig_iter3.APPLICATION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000              17326\n",
       "Thousands-Group     8638\n",
       "C2000               6074\n",
       "5Hundred-Group      1484\n",
       "C7000                777\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace if counts are less than 10\n",
    "replace_class_indicator_1 = ((df_orig_iter3['CLASSIFICATION'].value_counts() > 1000) & (df_orig_iter3['CLASSIFICATION'].value_counts() < 5000))\n",
    "# switch the index with values \n",
    "replace_class_1 = pd.Series(replace_class_indicator_1.index.values, index=replace_class_indicator_1 )\n",
    "# select only values that are less than 10 (aka true values)\n",
    "replace_class_1 = replace_class_1[replace_class_1.index.values == True]\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in replace_class_1:\n",
    "    df_orig_iter3.CLASSIFICATION = df_orig_iter3.CLASSIFICATION.replace(cls,\"Thousands-Group\")\n",
    "    \n",
    "# Determine which values to replace if counts are less than 10\n",
    "replace_class_indicator_2 = ((df_orig_iter3['CLASSIFICATION'].value_counts() > 10) & (df_orig_iter3['CLASSIFICATION'].value_counts() < 100))\n",
    "# switch the index with values \n",
    "replace_class_2 = pd.Series(replace_class_indicator_2.index.values, index=replace_class_indicator_2 )\n",
    "# select only values that are less than 10 (aka true values)\n",
    "replace_class_2 = replace_class_2[replace_class_2.index.values == True]\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in replace_class_2:\n",
    "    df_orig_iter3.CLASSIFICATION = df_orig_iter3.CLASSIFICATION.replace(cls,\"Hundred-Group\")\n",
    "\n",
    "# Determine which values to replace if counts are less than 10\n",
    "replace_class_indicator_3 = ((df_orig_iter3['CLASSIFICATION'].value_counts() > 100) & (df_orig_iter3['CLASSIFICATION'].value_counts() < 500))\n",
    "# switch the index with values \n",
    "replace_class_3 = pd.Series(replace_class_indicator_3.index.values, index=replace_class_indicator_3 )\n",
    "# select only values that are less than 10 (aka true values)\n",
    "replace_class_3 = replace_class_3[replace_class_3.index.values == True]\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in replace_class_3:\n",
    "    df_orig_iter3.CLASSIFICATION = df_orig_iter3.CLASSIFICATION.replace(cls,\"5Hundred-Group\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "df_orig_iter3.CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['APPLICATION_TYPE', 'AFFILIATION', 'CLASSIFICATION', 'USE_CASE',\n",
       "       'ORGANIZATION', 'INCOME_AMT', 'SPECIAL_CONSIDERATIONS'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable lists\n",
    "application_cat_iter3 = df_orig_iter3.select_dtypes(include=['object']).columns.values\n",
    "application_cat_iter3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE_5Hundreds-Group</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T13</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T9</th>\n",
       "      <th>APPLICATION_TYPE_Thousands-Group</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE_5Hundreds-Group  APPLICATION_TYPE_Other  \\\n",
       "0                               1.0                     0.0   \n",
       "1                               0.0                     0.0   \n",
       "2                               0.0                     0.0   \n",
       "3                               0.0                     0.0   \n",
       "4                               0.0                     0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T13  APPLICATION_TYPE_T3  APPLICATION_TYPE_T9  \\\n",
       "0                   0.0                  0.0                  0.0   \n",
       "1                   0.0                  1.0                  0.0   \n",
       "2                   0.0                  0.0                  0.0   \n",
       "3                   0.0                  1.0                  0.0   \n",
       "4                   0.0                  1.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_Thousands-Group  AFFILIATION_CompanySponsored  \\\n",
       "0                               0.0                           0.0   \n",
       "1                               0.0                           0.0   \n",
       "2                               1.0                           1.0   \n",
       "3                               0.0                           1.0   \n",
       "4                               0.0                           0.0   \n",
       "\n",
       "   AFFILIATION_Family/Parent  AFFILIATION_Independent  AFFILIATION_National  \\\n",
       "0                        0.0                      1.0                   0.0   \n",
       "1                        0.0                      1.0                   0.0   \n",
       "2                        0.0                      0.0                   0.0   \n",
       "3                        0.0                      0.0                   0.0   \n",
       "4                        0.0                      1.0                   0.0   \n",
       "\n",
       "   ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0  ...                0.0                     0.0                       0.0   \n",
       "1  ...                1.0                     0.0                       0.0   \n",
       "2  ...                0.0                     0.0                       0.0   \n",
       "3  ...                0.0                     1.0                       0.0   \n",
       "4  ...                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(df_orig_iter3[application_cat_iter3]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(application_cat_iter3)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE          6\n",
       "AFFILIATION               6\n",
       "CLASSIFICATION            5\n",
       "USE_CASE                  5\n",
       "ORGANIZATION              4\n",
       "INCOME_AMT                9\n",
       "SPECIAL_CONSIDERATIONS    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig_iter3[application_cat_iter3].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-452-0dadad1d172e>:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df_application_iter3.drop(application_cat, 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['APPLICATION_TYPE',\n",
       " 'AFFILIATION',\n",
       " 'CLASSIFICATION',\n",
       " 'USE_CASE',\n",
       " 'ORGANIZATION',\n",
       " 'INCOME_AMT',\n",
       " 'SPECIAL_CONSIDERATIONS']"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "df_application_iter3 = df_orig_iter3.merge(encode_df, left_index=True, right_index=True)\n",
    "df_application_iter3.drop(application_cat_iter3, 1, inplace=True)\n",
    "#df_application_iter1.head()\n",
    "application_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STATUS', 'ASK_AMT', 'IS_SUCCESSFUL',\n",
       "       'APPLICATION_TYPE_5Hundreds-Group', 'APPLICATION_TYPE_Other',\n",
       "       'APPLICATION_TYPE_T13', 'APPLICATION_TYPE_T3', 'APPLICATION_TYPE_T9',\n",
       "       'APPLICATION_TYPE_Thousands-Group', 'AFFILIATION_CompanySponsored',\n",
       "       'AFFILIATION_Family/Parent', 'AFFILIATION_Independent',\n",
       "       'AFFILIATION_National', 'AFFILIATION_Other', 'AFFILIATION_Regional',\n",
       "       'CLASSIFICATION_5Hundred-Group', 'CLASSIFICATION_C1000',\n",
       "       'CLASSIFICATION_C2000', 'CLASSIFICATION_C7000',\n",
       "       'CLASSIFICATION_Thousands-Group', 'USE_CASE_CommunityServ',\n",
       "       'USE_CASE_Heathcare', 'USE_CASE_Other', 'USE_CASE_Preservation',\n",
       "       'USE_CASE_ProductDev', 'ORGANIZATION_Association',\n",
       "       'ORGANIZATION_Co-operative', 'ORGANIZATION_Corporation',\n",
       "       'ORGANIZATION_Trust', 'INCOME_AMT_0', 'INCOME_AMT_1-9999',\n",
       "       'INCOME_AMT_10000-24999', 'INCOME_AMT_100000-499999',\n",
       "       'INCOME_AMT_10M-50M', 'INCOME_AMT_1M-5M', 'INCOME_AMT_25000-99999',\n",
       "       'INCOME_AMT_50M+', 'INCOME_AMT_5M-10M', 'SPECIAL_CONSIDERATIONS_N',\n",
       "       'SPECIAL_CONSIDERATIONS_Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_application_iter3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y3 = df_application_iter3[\"IS_SUCCESSFUL\"].values\n",
    "X3 = df_application_iter3.drop([\"IS_SUCCESSFUL\"], axis=1)\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X3, y3, random_state=50, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler_3 = scaler.fit(X_train_3)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled_3 = X_scaler_3.transform(X_train_3)\n",
    "X_test_scaled_3 = X_scaler_3.transform(X_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "27\n",
      "19\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_57 (Dense)            (None, 27)                1080      \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 19)                532       \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,632\n",
      "Trainable params: 1,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "no_of_features = len(X_train_scaled_3[0])\n",
    "no_of_nodes_layer1 = int(no_of_features * 0.70)\n",
    "no_of_nodes_layer2 = int(no_of_features * 0.50)\n",
    "no_of_nodes_layer3 = int(no_of_features * 0.25)\n",
    "no_of_output_nodes = 1\n",
    "\n",
    "### print all the layers input\n",
    "print(no_of_features)\n",
    "print(no_of_nodes_layer1)\n",
    "print(no_of_nodes_layer2)\n",
    "\n",
    "nn3 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=no_of_nodes_layer1, activation='relu', input_dim=no_of_features))\n",
    "\n",
    "\n",
    "# Second hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=no_of_nodes_layer2, activation='relu'))\n",
    "\n",
    "# 3 hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=no_of_nodes_layer3, activation='relu'))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn3.add(tf.keras.layers.Dense(units=no_of_output_nodes, activation='sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"AlphabetSoupCharity_Optimization.h5\", verbose=1, save_weights_only=True, save_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "858/858 [==============================] - 1s 937us/step - loss: 0.5989 - accuracy: 0.6981\n",
      "Epoch 2/500\n",
      "858/858 [==============================] - 1s 922us/step - loss: 0.5807 - accuracy: 0.7109\n",
      "Epoch 3/500\n",
      "858/858 [==============================] - 1s 872us/step - loss: 0.5780 - accuracy: 0.7138\n",
      "Epoch 4/500\n",
      "858/858 [==============================] - 1s 893us/step - loss: 0.5758 - accuracy: 0.7151\n",
      "Epoch 5/500\n",
      "858/858 [==============================] - 1s 897us/step - loss: 0.5740 - accuracy: 0.7160\n",
      "Epoch 6/500\n",
      "858/858 [==============================] - 1s 868us/step - loss: 0.5727 - accuracy: 0.7176\n",
      "Epoch 7/500\n",
      "858/858 [==============================] - 1s 911us/step - loss: 0.5726 - accuracy: 0.7184\n",
      "Epoch 8/500\n",
      "858/858 [==============================] - 1s 943us/step - loss: 0.5715 - accuracy: 0.7186\n",
      "Epoch 9/500\n",
      "858/858 [==============================] - 1s 918us/step - loss: 0.5710 - accuracy: 0.7180\n",
      "Epoch 10/500\n",
      "858/858 [==============================] - 1s 915us/step - loss: 0.5707 - accuracy: 0.7191\n",
      "Epoch 11/500\n",
      "858/858 [==============================] - 1s 892us/step - loss: 0.5699 - accuracy: 0.7193\n",
      "Epoch 12/500\n",
      "858/858 [==============================] - 1s 937us/step - loss: 0.5691 - accuracy: 0.7196\n",
      "Epoch 13/500\n",
      "858/858 [==============================] - 1s 926us/step - loss: 0.5695 - accuracy: 0.7193\n",
      "Epoch 14/500\n",
      "858/858 [==============================] - 1s 928us/step - loss: 0.5693 - accuracy: 0.7207\n",
      "Epoch 15/500\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5689 - accuracy: 0.7193\n",
      "Epoch 16/500\n",
      "858/858 [==============================] - 1s 942us/step - loss: 0.5685 - accuracy: 0.7197\n",
      "Epoch 17/500\n",
      "858/858 [==============================] - 1s 906us/step - loss: 0.5686 - accuracy: 0.7201\n",
      "Epoch 18/500\n",
      "858/858 [==============================] - 1s 923us/step - loss: 0.5681 - accuracy: 0.7212\n",
      "Epoch 19/500\n",
      "858/858 [==============================] - 1s 924us/step - loss: 0.5680 - accuracy: 0.7205\n",
      "Epoch 20/500\n",
      "858/858 [==============================] - 1s 890us/step - loss: 0.5683 - accuracy: 0.7208\n",
      "Epoch 21/500\n",
      "858/858 [==============================] - 1s 906us/step - loss: 0.5674 - accuracy: 0.7207\n",
      "Epoch 22/500\n",
      "858/858 [==============================] - 1s 870us/step - loss: 0.5675 - accuracy: 0.7212\n",
      "Epoch 23/500\n",
      "858/858 [==============================] - 1s 978us/step - loss: 0.5673 - accuracy: 0.7217\n",
      "Epoch 24/500\n",
      "858/858 [==============================] - 1s 911us/step - loss: 0.5671 - accuracy: 0.7217\n",
      "Epoch 25/500\n",
      "858/858 [==============================] - 1s 874us/step - loss: 0.5666 - accuracy: 0.7212\n",
      "Epoch 26/500\n",
      "858/858 [==============================] - 1s 890us/step - loss: 0.5668 - accuracy: 0.7216\n",
      "Epoch 27/500\n",
      "858/858 [==============================] - 1s 897us/step - loss: 0.5667 - accuracy: 0.7220\n",
      "Epoch 28/500\n",
      "858/858 [==============================] - 1s 892us/step - loss: 0.5665 - accuracy: 0.7220\n",
      "Epoch 29/500\n",
      "858/858 [==============================] - 1s 921us/step - loss: 0.5665 - accuracy: 0.7218\n",
      "Epoch 30/500\n",
      "858/858 [==============================] - 1s 917us/step - loss: 0.5662 - accuracy: 0.7217\n",
      "Epoch 31/500\n",
      "858/858 [==============================] - 1s 890us/step - loss: 0.5662 - accuracy: 0.7216\n",
      "Epoch 32/500\n",
      "858/858 [==============================] - 1s 906us/step - loss: 0.5660 - accuracy: 0.7217\n",
      "Epoch 33/500\n",
      "858/858 [==============================] - 1s 877us/step - loss: 0.5660 - accuracy: 0.7229\n",
      "Epoch 34/500\n",
      "858/858 [==============================] - 1s 906us/step - loss: 0.5657 - accuracy: 0.7226\n",
      "Epoch 35/500\n",
      "858/858 [==============================] - 1s 878us/step - loss: 0.5655 - accuracy: 0.7223\n",
      "Epoch 36/500\n",
      "858/858 [==============================] - 1s 853us/step - loss: 0.5653 - accuracy: 0.7226\n",
      "Epoch 37/500\n",
      "858/858 [==============================] - 1s 885us/step - loss: 0.5653 - accuracy: 0.7219\n",
      "Epoch 38/500\n",
      "858/858 [==============================] - 1s 872us/step - loss: 0.5654 - accuracy: 0.7224\n",
      "Epoch 39/500\n",
      "858/858 [==============================] - 1s 912us/step - loss: 0.5652 - accuracy: 0.7220\n",
      "Epoch 40/500\n",
      "858/858 [==============================] - 1s 959us/step - loss: 0.5652 - accuracy: 0.7220\n",
      "Epoch 41/500\n",
      "858/858 [==============================] - 1s 910us/step - loss: 0.5648 - accuracy: 0.7221\n",
      "Epoch 42/500\n",
      "858/858 [==============================] - 1s 882us/step - loss: 0.5650 - accuracy: 0.7221\n",
      "Epoch 43/500\n",
      "858/858 [==============================] - 1s 893us/step - loss: 0.5645 - accuracy: 0.7243\n",
      "Epoch 44/500\n",
      "858/858 [==============================] - 1s 876us/step - loss: 0.5649 - accuracy: 0.7222\n",
      "Epoch 45/500\n",
      "858/858 [==============================] - 1s 896us/step - loss: 0.5648 - accuracy: 0.7227\n",
      "Epoch 46/500\n",
      "858/858 [==============================] - 1s 881us/step - loss: 0.5646 - accuracy: 0.7226\n",
      "Epoch 47/500\n",
      "858/858 [==============================] - 1s 894us/step - loss: 0.5645 - accuracy: 0.7223\n",
      "Epoch 48/500\n",
      "858/858 [==============================] - 1s 909us/step - loss: 0.5646 - accuracy: 0.7233\n",
      "Epoch 49/500\n",
      "858/858 [==============================] - 1s 913us/step - loss: 0.5644 - accuracy: 0.7236\n",
      "Epoch 50/500\n",
      "858/858 [==============================] - 1s 893us/step - loss: 0.5644 - accuracy: 0.7227\n",
      "Epoch 51/500\n",
      "858/858 [==============================] - 1s 887us/step - loss: 0.5641 - accuracy: 0.7231\n",
      "Epoch 52/500\n",
      "858/858 [==============================] - 1s 867us/step - loss: 0.5641 - accuracy: 0.7235\n",
      "Epoch 53/500\n",
      "858/858 [==============================] - 1s 889us/step - loss: 0.5637 - accuracy: 0.7239\n",
      "Epoch 54/500\n",
      "858/858 [==============================] - 1s 901us/step - loss: 0.5641 - accuracy: 0.7227\n",
      "Epoch 55/500\n",
      "858/858 [==============================] - 1s 880us/step - loss: 0.5636 - accuracy: 0.7237\n",
      "Epoch 56/500\n",
      "858/858 [==============================] - 1s 908us/step - loss: 0.5639 - accuracy: 0.7238\n",
      "Epoch 57/500\n",
      "858/858 [==============================] - 1s 886us/step - loss: 0.5636 - accuracy: 0.7239\n",
      "Epoch 58/500\n",
      "858/858 [==============================] - 1s 904us/step - loss: 0.5639 - accuracy: 0.7229\n",
      "Epoch 59/500\n",
      "858/858 [==============================] - 1s 889us/step - loss: 0.5635 - accuracy: 0.7230\n",
      "Epoch 60/500\n",
      "858/858 [==============================] - 1s 917us/step - loss: 0.5634 - accuracy: 0.7235\n",
      "Epoch 61/500\n",
      "858/858 [==============================] - 1s 914us/step - loss: 0.5633 - accuracy: 0.7239\n",
      "Epoch 62/500\n",
      "858/858 [==============================] - 1s 915us/step - loss: 0.5632 - accuracy: 0.7238\n",
      "Epoch 63/500\n",
      "858/858 [==============================] - 1s 909us/step - loss: 0.5635 - accuracy: 0.7235\n",
      "Epoch 64/500\n",
      "858/858 [==============================] - 1s 912us/step - loss: 0.5633 - accuracy: 0.7231\n",
      "Epoch 65/500\n",
      "858/858 [==============================] - 1s 879us/step - loss: 0.5633 - accuracy: 0.7242\n",
      "Epoch 66/500\n",
      "858/858 [==============================] - 1s 895us/step - loss: 0.5629 - accuracy: 0.7236\n",
      "Epoch 67/500\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5632 - accuracy: 0.7241\n",
      "Epoch 68/500\n",
      "858/858 [==============================] - 1s 866us/step - loss: 0.5631 - accuracy: 0.7229\n",
      "Epoch 69/500\n",
      "858/858 [==============================] - 1s 908us/step - loss: 0.5631 - accuracy: 0.7231\n",
      "Epoch 70/500\n",
      "858/858 [==============================] - 1s 928us/step - loss: 0.5630 - accuracy: 0.7245\n",
      "Epoch 71/500\n",
      "858/858 [==============================] - 1s 862us/step - loss: 0.5630 - accuracy: 0.7245\n",
      "Epoch 72/500\n",
      "858/858 [==============================] - 1s 891us/step - loss: 0.5628 - accuracy: 0.7241\n",
      "Epoch 73/500\n",
      "858/858 [==============================] - 1s 892us/step - loss: 0.5630 - accuracy: 0.7235\n",
      "Epoch 74/500\n",
      "858/858 [==============================] - 1s 895us/step - loss: 0.5630 - accuracy: 0.7236\n",
      "Epoch 75/500\n",
      "858/858 [==============================] - 1s 892us/step - loss: 0.5627 - accuracy: 0.7233\n",
      "Epoch 76/500\n",
      "858/858 [==============================] - 1s 877us/step - loss: 0.5628 - accuracy: 0.7236\n",
      "Epoch 77/500\n",
      "858/858 [==============================] - 1s 900us/step - loss: 0.5627 - accuracy: 0.7225\n",
      "Epoch 78/500\n",
      "858/858 [==============================] - 1s 894us/step - loss: 0.5628 - accuracy: 0.7239\n",
      "Epoch 79/500\n",
      "858/858 [==============================] - 1s 905us/step - loss: 0.5626 - accuracy: 0.7238\n",
      "Epoch 80/500\n",
      "858/858 [==============================] - 1s 930us/step - loss: 0.5628 - accuracy: 0.7241\n",
      "Epoch 81/500\n",
      "858/858 [==============================] - 1s 930us/step - loss: 0.5625 - accuracy: 0.7240\n",
      "Epoch 82/500\n",
      "858/858 [==============================] - 1s 878us/step - loss: 0.5625 - accuracy: 0.7241\n",
      "Epoch 83/500\n",
      "858/858 [==============================] - 1s 882us/step - loss: 0.5625 - accuracy: 0.7236\n",
      "Epoch 84/500\n",
      "858/858 [==============================] - 1s 883us/step - loss: 0.5624 - accuracy: 0.7236\n",
      "Epoch 85/500\n",
      "858/858 [==============================] - 1s 890us/step - loss: 0.5624 - accuracy: 0.7238\n",
      "Epoch 86/500\n",
      "858/858 [==============================] - 1s 876us/step - loss: 0.5621 - accuracy: 0.7241\n",
      "Epoch 87/500\n",
      "858/858 [==============================] - 1s 888us/step - loss: 0.5622 - accuracy: 0.7244\n",
      "Epoch 88/500\n",
      "858/858 [==============================] - 1s 898us/step - loss: 0.5621 - accuracy: 0.7246\n",
      "Epoch 89/500\n",
      "858/858 [==============================] - 1s 885us/step - loss: 0.5623 - accuracy: 0.7248\n",
      "Epoch 90/500\n",
      "858/858 [==============================] - 1s 911us/step - loss: 0.5622 - accuracy: 0.7238\n",
      "Epoch 91/500\n",
      "858/858 [==============================] - 1s 928us/step - loss: 0.5619 - accuracy: 0.7247\n",
      "Epoch 92/500\n",
      "858/858 [==============================] - 1s 895us/step - loss: 0.5623 - accuracy: 0.7234\n",
      "Epoch 93/500\n",
      "858/858 [==============================] - 1s 895us/step - loss: 0.5618 - accuracy: 0.7246\n",
      "Epoch 94/500\n",
      "858/858 [==============================] - 1s 889us/step - loss: 0.5619 - accuracy: 0.7246\n",
      "Epoch 95/500\n",
      "858/858 [==============================] - 1s 893us/step - loss: 0.5618 - accuracy: 0.7251\n",
      "Epoch 96/500\n",
      "858/858 [==============================] - 1s 885us/step - loss: 0.5619 - accuracy: 0.7251\n",
      "Epoch 97/500\n",
      "858/858 [==============================] - 1s 898us/step - loss: 0.5620 - accuracy: 0.7242\n",
      "Epoch 98/500\n",
      "858/858 [==============================] - 1s 908us/step - loss: 0.5618 - accuracy: 0.7243\n",
      "Epoch 99/500\n",
      "858/858 [==============================] - 1s 910us/step - loss: 0.5617 - accuracy: 0.7247\n",
      "Epoch 100/500\n",
      "858/858 [==============================] - 1s 875us/step - loss: 0.5619 - accuracy: 0.7246\n",
      "Epoch 101/500\n",
      "858/858 [==============================] - 1s 987us/step - loss: 0.5616 - accuracy: 0.7241\n",
      "Epoch 102/500\n",
      "858/858 [==============================] - 1s 938us/step - loss: 0.5617 - accuracy: 0.7240\n",
      "Epoch 103/500\n",
      "858/858 [==============================] - 1s 861us/step - loss: 0.5618 - accuracy: 0.7248\n",
      "Epoch 104/500\n",
      "858/858 [==============================] - 1s 921us/step - loss: 0.5612 - accuracy: 0.7240\n",
      "Epoch 105/500\n",
      "858/858 [==============================] - 1s 895us/step - loss: 0.5617 - accuracy: 0.7239\n",
      "Epoch 106/500\n",
      "858/858 [==============================] - 1s 918us/step - loss: 0.5614 - accuracy: 0.7246\n",
      "Epoch 107/500\n",
      "858/858 [==============================] - 1s 906us/step - loss: 0.5614 - accuracy: 0.7239\n",
      "Epoch 108/500\n",
      "858/858 [==============================] - 1s 885us/step - loss: 0.5616 - accuracy: 0.7252\n",
      "Epoch 109/500\n",
      "858/858 [==============================] - 1s 887us/step - loss: 0.5612 - accuracy: 0.7244\n",
      "Epoch 110/500\n",
      "858/858 [==============================] - 1s 892us/step - loss: 0.5616 - accuracy: 0.7236\n",
      "Epoch 111/500\n",
      "858/858 [==============================] - 1s 893us/step - loss: 0.5613 - accuracy: 0.7245\n",
      "Epoch 112/500\n",
      "858/858 [==============================] - 1s 928us/step - loss: 0.5613 - accuracy: 0.7244\n",
      "Epoch 113/500\n",
      "858/858 [==============================] - 1s 918us/step - loss: 0.5613 - accuracy: 0.7248\n",
      "Epoch 114/500\n",
      "858/858 [==============================] - 1s 887us/step - loss: 0.5614 - accuracy: 0.7248\n",
      "Epoch 115/500\n",
      "858/858 [==============================] - 1s 904us/step - loss: 0.5612 - accuracy: 0.7250\n",
      "Epoch 116/500\n",
      "858/858 [==============================] - 1s 872us/step - loss: 0.5612 - accuracy: 0.7250\n",
      "Epoch 117/500\n",
      "858/858 [==============================] - 1s 870us/step - loss: 0.5612 - accuracy: 0.7237\n",
      "Epoch 118/500\n",
      "858/858 [==============================] - 1s 971us/step - loss: 0.5609 - accuracy: 0.7239\n",
      "Epoch 119/500\n",
      "858/858 [==============================] - 1s 895us/step - loss: 0.5611 - accuracy: 0.7248\n",
      "Epoch 120/500\n",
      "858/858 [==============================] - 1s 922us/step - loss: 0.5612 - accuracy: 0.7238\n",
      "Epoch 121/500\n",
      "858/858 [==============================] - 1s 899us/step - loss: 0.5612 - accuracy: 0.7246\n",
      "Epoch 122/500\n",
      "858/858 [==============================] - 1s 919us/step - loss: 0.5610 - accuracy: 0.7247\n",
      "Epoch 123/500\n",
      "858/858 [==============================] - 1s 938us/step - loss: 0.5611 - accuracy: 0.7248\n",
      "Epoch 124/500\n",
      "858/858 [==============================] - 1s 863us/step - loss: 0.5609 - accuracy: 0.7251\n",
      "Epoch 125/500\n",
      "858/858 [==============================] - 1s 915us/step - loss: 0.5610 - accuracy: 0.7246\n",
      "Epoch 126/500\n",
      "858/858 [==============================] - 1s 901us/step - loss: 0.5610 - accuracy: 0.7245\n",
      "Epoch 127/500\n",
      "858/858 [==============================] - 1s 871us/step - loss: 0.5609 - accuracy: 0.7245\n",
      "Epoch 128/500\n",
      "858/858 [==============================] - 1s 913us/step - loss: 0.5610 - accuracy: 0.7243\n",
      "Epoch 129/500\n",
      "858/858 [==============================] - 1s 900us/step - loss: 0.5607 - accuracy: 0.7244\n",
      "Epoch 130/500\n",
      "858/858 [==============================] - 1s 898us/step - loss: 0.5608 - accuracy: 0.7248\n",
      "Epoch 131/500\n",
      "858/858 [==============================] - 1s 890us/step - loss: 0.5608 - accuracy: 0.7254\n",
      "Epoch 132/500\n",
      "858/858 [==============================] - 1s 873us/step - loss: 0.5605 - accuracy: 0.7231\n",
      "Epoch 133/500\n",
      "858/858 [==============================] - 1s 896us/step - loss: 0.5608 - accuracy: 0.7244\n",
      "Epoch 134/500\n",
      "858/858 [==============================] - 1s 914us/step - loss: 0.5605 - accuracy: 0.7241\n",
      "Epoch 135/500\n",
      "858/858 [==============================] - 1s 859us/step - loss: 0.5607 - accuracy: 0.7242\n",
      "Epoch 136/500\n",
      "858/858 [==============================] - 1s 899us/step - loss: 0.5606 - accuracy: 0.7258\n",
      "Epoch 137/500\n",
      "858/858 [==============================] - 1s 939us/step - loss: 0.5606 - accuracy: 0.7238\n",
      "Epoch 138/500\n",
      "858/858 [==============================] - 1s 901us/step - loss: 0.5607 - accuracy: 0.7238\n",
      "Epoch 139/500\n",
      "858/858 [==============================] - 1s 911us/step - loss: 0.5606 - accuracy: 0.7241\n",
      "Epoch 140/500\n",
      "858/858 [==============================] - 1s 879us/step - loss: 0.5605 - accuracy: 0.7250\n",
      "Epoch 141/500\n",
      "858/858 [==============================] - 1s 900us/step - loss: 0.5605 - accuracy: 0.7247\n",
      "Epoch 142/500\n",
      "858/858 [==============================] - 1s 870us/step - loss: 0.5604 - accuracy: 0.7251\n",
      "Epoch 143/500\n",
      "858/858 [==============================] - 1s 880us/step - loss: 0.5606 - accuracy: 0.7246\n",
      "Epoch 144/500\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5605 - accuracy: 0.7246\n",
      "Epoch 145/500\n",
      "858/858 [==============================] - 1s 994us/step - loss: 0.5603 - accuracy: 0.7250\n",
      "Epoch 146/500\n",
      "858/858 [==============================] - 1s 884us/step - loss: 0.5607 - accuracy: 0.7251\n",
      "Epoch 147/500\n",
      "858/858 [==============================] - 1s 914us/step - loss: 0.5605 - accuracy: 0.7245\n",
      "Epoch 148/500\n",
      "858/858 [==============================] - 1s 891us/step - loss: 0.5602 - accuracy: 0.7252\n",
      "Epoch 149/500\n",
      "858/858 [==============================] - 1s 887us/step - loss: 0.5603 - accuracy: 0.7255\n",
      "Epoch 150/500\n",
      "858/858 [==============================] - 1s 923us/step - loss: 0.5604 - accuracy: 0.7249\n",
      "Epoch 151/500\n",
      "858/858 [==============================] - 1s 883us/step - loss: 0.5604 - accuracy: 0.7252\n",
      "Epoch 152/500\n",
      "858/858 [==============================] - 1s 925us/step - loss: 0.5602 - accuracy: 0.7250\n",
      "Epoch 153/500\n",
      "858/858 [==============================] - 1s 903us/step - loss: 0.5604 - accuracy: 0.7248\n",
      "Epoch 154/500\n",
      "858/858 [==============================] - 1s 895us/step - loss: 0.5602 - accuracy: 0.7252\n",
      "Epoch 155/500\n",
      "858/858 [==============================] - 1s 924us/step - loss: 0.5601 - accuracy: 0.7246\n",
      "Epoch 156/500\n",
      "858/858 [==============================] - 1s 862us/step - loss: 0.5602 - accuracy: 0.7248\n",
      "Epoch 157/500\n",
      "858/858 [==============================] - 1s 902us/step - loss: 0.5603 - accuracy: 0.7242\n",
      "Epoch 158/500\n",
      "858/858 [==============================] - 1s 886us/step - loss: 0.5604 - accuracy: 0.7244\n",
      "Epoch 159/500\n",
      "858/858 [==============================] - 1s 860us/step - loss: 0.5603 - accuracy: 0.7245\n",
      "Epoch 160/500\n",
      "858/858 [==============================] - 1s 881us/step - loss: 0.5603 - accuracy: 0.7252\n",
      "Epoch 161/500\n",
      "858/858 [==============================] - 1s 966us/step - loss: 0.5601 - accuracy: 0.7248\n",
      "Epoch 162/500\n",
      "858/858 [==============================] - 1s 934us/step - loss: 0.5601 - accuracy: 0.7243\n",
      "Epoch 163/500\n",
      "858/858 [==============================] - 1s 897us/step - loss: 0.5601 - accuracy: 0.7250\n",
      "Epoch 164/500\n",
      "858/858 [==============================] - 1s 885us/step - loss: 0.5603 - accuracy: 0.7251\n",
      "Epoch 165/500\n",
      "858/858 [==============================] - 1s 910us/step - loss: 0.5600 - accuracy: 0.7251\n",
      "Epoch 166/500\n",
      "858/858 [==============================] - 1s 906us/step - loss: 0.5599 - accuracy: 0.7259\n",
      "Epoch 167/500\n",
      "858/858 [==============================] - 1s 879us/step - loss: 0.5600 - accuracy: 0.7249\n",
      "Epoch 168/500\n",
      "858/858 [==============================] - 1s 902us/step - loss: 0.5600 - accuracy: 0.7252\n",
      "Epoch 169/500\n",
      "858/858 [==============================] - 1s 908us/step - loss: 0.5599 - accuracy: 0.7255\n",
      "Epoch 170/500\n",
      "858/858 [==============================] - 1s 899us/step - loss: 0.5600 - accuracy: 0.7250\n",
      "Epoch 171/500\n",
      "858/858 [==============================] - 1s 907us/step - loss: 0.5599 - accuracy: 0.7255\n",
      "Epoch 172/500\n",
      "858/858 [==============================] - 1s 886us/step - loss: 0.5600 - accuracy: 0.7246\n",
      "Epoch 173/500\n",
      "858/858 [==============================] - 1s 903us/step - loss: 0.5600 - accuracy: 0.7249\n",
      "Epoch 174/500\n",
      "858/858 [==============================] - 1s 868us/step - loss: 0.5600 - accuracy: 0.7256\n",
      "Epoch 175/500\n",
      "858/858 [==============================] - 1s 878us/step - loss: 0.5598 - accuracy: 0.7256\n",
      "Epoch 176/500\n",
      "858/858 [==============================] - 1s 903us/step - loss: 0.5599 - accuracy: 0.7248\n",
      "Epoch 177/500\n",
      "858/858 [==============================] - 1s 897us/step - loss: 0.5598 - accuracy: 0.7257\n",
      "Epoch 178/500\n",
      "858/858 [==============================] - 1s 887us/step - loss: 0.5599 - accuracy: 0.7247\n",
      "Epoch 179/500\n",
      "858/858 [==============================] - 1s 886us/step - loss: 0.5598 - accuracy: 0.7256\n",
      "Epoch 180/500\n",
      "858/858 [==============================] - 1s 953us/step - loss: 0.5599 - accuracy: 0.7251\n",
      "Epoch 181/500\n",
      "858/858 [==============================] - 1s 866us/step - loss: 0.5597 - accuracy: 0.7245\n",
      "Epoch 182/500\n",
      "858/858 [==============================] - 1s 948us/step - loss: 0.5599 - accuracy: 0.7254\n",
      "Epoch 183/500\n",
      "858/858 [==============================] - 1s 900us/step - loss: 0.5597 - accuracy: 0.7254\n",
      "Epoch 184/500\n",
      "858/858 [==============================] - 1s 879us/step - loss: 0.5596 - accuracy: 0.7247\n",
      "Epoch 185/500\n",
      "858/858 [==============================] - 1s 895us/step - loss: 0.5599 - accuracy: 0.7249\n",
      "Epoch 186/500\n",
      "858/858 [==============================] - 1s 871us/step - loss: 0.5597 - accuracy: 0.7250\n",
      "Epoch 187/500\n",
      "858/858 [==============================] - 1s 895us/step - loss: 0.5597 - accuracy: 0.7250\n",
      "Epoch 188/500\n",
      "858/858 [==============================] - 1s 874us/step - loss: 0.5595 - accuracy: 0.7251\n",
      "Epoch 189/500\n",
      "858/858 [==============================] - 1s 889us/step - loss: 0.5595 - accuracy: 0.7252\n",
      "Epoch 190/500\n",
      "858/858 [==============================] - 1s 890us/step - loss: 0.5597 - accuracy: 0.7246\n",
      "Epoch 191/500\n",
      "858/858 [==============================] - 1s 882us/step - loss: 0.5598 - accuracy: 0.7251\n",
      "Epoch 192/500\n",
      "858/858 [==============================] - 1s 936us/step - loss: 0.5596 - accuracy: 0.7254\n",
      "Epoch 193/500\n",
      "858/858 [==============================] - 1s 917us/step - loss: 0.5596 - accuracy: 0.7257\n",
      "Epoch 194/500\n",
      "858/858 [==============================] - 1s 886us/step - loss: 0.5598 - accuracy: 0.7244\n",
      "Epoch 195/500\n",
      "858/858 [==============================] - 1s 925us/step - loss: 0.5597 - accuracy: 0.7249\n",
      "Epoch 196/500\n",
      "858/858 [==============================] - 1s 970us/step - loss: 0.5595 - accuracy: 0.7255\n",
      "Epoch 197/500\n",
      "858/858 [==============================] - 1s 862us/step - loss: 0.5595 - accuracy: 0.7256\n",
      "Epoch 198/500\n",
      "858/858 [==============================] - 1s 888us/step - loss: 0.5595 - accuracy: 0.7253\n",
      "Epoch 199/500\n",
      "858/858 [==============================] - 1s 909us/step - loss: 0.5596 - accuracy: 0.7254\n",
      "Epoch 200/500\n",
      "858/858 [==============================] - 1s 861us/step - loss: 0.5595 - accuracy: 0.7248\n",
      "Epoch 201/500\n",
      "858/858 [==============================] - 1s 915us/step - loss: 0.5594 - accuracy: 0.7260\n",
      "Epoch 202/500\n",
      "858/858 [==============================] - 1s 983us/step - loss: 0.5595 - accuracy: 0.7254\n",
      "Epoch 203/500\n",
      "858/858 [==============================] - 1s 896us/step - loss: 0.5596 - accuracy: 0.7251\n",
      "Epoch 204/500\n",
      "858/858 [==============================] - 1s 917us/step - loss: 0.5595 - accuracy: 0.7251\n",
      "Epoch 205/500\n",
      "858/858 [==============================] - 1s 866us/step - loss: 0.5594 - accuracy: 0.7257\n",
      "Epoch 206/500\n",
      "858/858 [==============================] - 1s 912us/step - loss: 0.5594 - accuracy: 0.7254\n",
      "Epoch 207/500\n",
      "858/858 [==============================] - 1s 895us/step - loss: 0.5594 - accuracy: 0.7252\n",
      "Epoch 208/500\n",
      "858/858 [==============================] - 1s 900us/step - loss: 0.5593 - accuracy: 0.7248\n",
      "Epoch 209/500\n",
      "858/858 [==============================] - 1s 960us/step - loss: 0.5595 - accuracy: 0.7245\n",
      "Epoch 210/500\n",
      "858/858 [==============================] - 1s 879us/step - loss: 0.5595 - accuracy: 0.7250\n",
      "Epoch 211/500\n",
      "858/858 [==============================] - 1s 884us/step - loss: 0.5593 - accuracy: 0.7248\n",
      "Epoch 212/500\n",
      "858/858 [==============================] - 1s 892us/step - loss: 0.5594 - accuracy: 0.7252\n",
      "Epoch 213/500\n",
      "858/858 [==============================] - 1s 869us/step - loss: 0.5594 - accuracy: 0.7258\n",
      "Epoch 214/500\n",
      "858/858 [==============================] - 1s 910us/step - loss: 0.5592 - accuracy: 0.7255\n",
      "Epoch 215/500\n",
      "858/858 [==============================] - 1s 912us/step - loss: 0.5592 - accuracy: 0.7251\n",
      "Epoch 216/500\n",
      "858/858 [==============================] - 1s 884us/step - loss: 0.5593 - accuracy: 0.7245\n",
      "Epoch 217/500\n",
      "858/858 [==============================] - 1s 940us/step - loss: 0.5593 - accuracy: 0.7258\n",
      "Epoch 218/500\n",
      "858/858 [==============================] - 1s 912us/step - loss: 0.5594 - accuracy: 0.7256\n",
      "Epoch 219/500\n",
      "858/858 [==============================] - 1s 889us/step - loss: 0.5594 - accuracy: 0.7257\n",
      "Epoch 220/500\n",
      "858/858 [==============================] - 1s 887us/step - loss: 0.5593 - accuracy: 0.7253\n",
      "Epoch 221/500\n",
      "858/858 [==============================] - 1s 983us/step - loss: 0.5593 - accuracy: 0.7255\n",
      "Epoch 222/500\n",
      "858/858 [==============================] - 1s 974us/step - loss: 0.5591 - accuracy: 0.7253\n",
      "Epoch 223/500\n",
      "858/858 [==============================] - 1s 895us/step - loss: 0.5592 - accuracy: 0.7260\n",
      "Epoch 224/500\n",
      "858/858 [==============================] - 1s 897us/step - loss: 0.5593 - accuracy: 0.7250\n",
      "Epoch 225/500\n",
      "858/858 [==============================] - 1s 937us/step - loss: 0.5591 - accuracy: 0.7258\n",
      "Epoch 226/500\n",
      "858/858 [==============================] - 1s 899us/step - loss: 0.5592 - accuracy: 0.7255\n",
      "Epoch 227/500\n",
      "858/858 [==============================] - 1s 878us/step - loss: 0.5591 - accuracy: 0.7254\n",
      "Epoch 228/500\n",
      "858/858 [==============================] - 1s 897us/step - loss: 0.5592 - accuracy: 0.7261\n",
      "Epoch 229/500\n",
      "858/858 [==============================] - 1s 898us/step - loss: 0.5591 - accuracy: 0.7255\n",
      "Epoch 230/500\n",
      "858/858 [==============================] - 1s 887us/step - loss: 0.5592 - accuracy: 0.7251\n",
      "Epoch 231/500\n",
      "858/858 [==============================] - 1s 902us/step - loss: 0.5591 - accuracy: 0.7258\n",
      "Epoch 232/500\n",
      "858/858 [==============================] - 1s 887us/step - loss: 0.5591 - accuracy: 0.7256\n",
      "Epoch 233/500\n",
      "858/858 [==============================] - 1s 907us/step - loss: 0.5590 - accuracy: 0.7255\n",
      "Epoch 234/500\n",
      "858/858 [==============================] - 1s 939us/step - loss: 0.5592 - accuracy: 0.7252\n",
      "Epoch 235/500\n",
      "858/858 [==============================] - 1s 911us/step - loss: 0.5591 - accuracy: 0.7259\n",
      "Epoch 236/500\n",
      "858/858 [==============================] - 1s 904us/step - loss: 0.5593 - accuracy: 0.7256\n",
      "Epoch 237/500\n",
      "858/858 [==============================] - 1s 884us/step - loss: 0.5592 - accuracy: 0.7254\n",
      "Epoch 238/500\n",
      "858/858 [==============================] - 1s 886us/step - loss: 0.5592 - accuracy: 0.7257\n",
      "Epoch 239/500\n",
      "858/858 [==============================] - 1s 908us/step - loss: 0.5590 - accuracy: 0.7255\n",
      "Epoch 240/500\n",
      "858/858 [==============================] - 1s 887us/step - loss: 0.5590 - accuracy: 0.7253\n",
      "Epoch 241/500\n",
      "858/858 [==============================] - 1s 909us/step - loss: 0.5590 - accuracy: 0.7254\n",
      "Epoch 242/500\n",
      "858/858 [==============================] - 1s 930us/step - loss: 0.5589 - accuracy: 0.7254\n",
      "Epoch 243/500\n",
      "858/858 [==============================] - 1s 869us/step - loss: 0.5592 - accuracy: 0.7256\n",
      "Epoch 244/500\n",
      "858/858 [==============================] - 1s 922us/step - loss: 0.5590 - accuracy: 0.7262\n",
      "Epoch 245/500\n",
      "858/858 [==============================] - 1s 892us/step - loss: 0.5591 - accuracy: 0.7254\n",
      "Epoch 246/500\n",
      "858/858 [==============================] - 1s 893us/step - loss: 0.5590 - accuracy: 0.7254\n",
      "Epoch 247/500\n",
      "858/858 [==============================] - 1s 899us/step - loss: 0.5590 - accuracy: 0.7258\n",
      "Epoch 248/500\n",
      "858/858 [==============================] - 1s 891us/step - loss: 0.5590 - accuracy: 0.7254\n",
      "Epoch 249/500\n",
      "858/858 [==============================] - 1s 914us/step - loss: 0.5590 - accuracy: 0.7257\n",
      "Epoch 250/500\n",
      "858/858 [==============================] - 1s 940us/step - loss: 0.5588 - accuracy: 0.7264\n",
      "Epoch 251/500\n",
      "858/858 [==============================] - 1s 876us/step - loss: 0.5589 - accuracy: 0.7248\n",
      "Epoch 252/500\n",
      "858/858 [==============================] - 1s 906us/step - loss: 0.5590 - accuracy: 0.7251\n",
      "Epoch 253/500\n",
      "858/858 [==============================] - 1s 910us/step - loss: 0.5589 - accuracy: 0.7260\n",
      "Epoch 254/500\n",
      "858/858 [==============================] - 1s 880us/step - loss: 0.5590 - accuracy: 0.7257\n",
      "Epoch 255/500\n",
      "858/858 [==============================] - 1s 900us/step - loss: 0.5590 - accuracy: 0.7261\n",
      "Epoch 256/500\n",
      "858/858 [==============================] - 1s 878us/step - loss: 0.5591 - accuracy: 0.7253\n",
      "Epoch 257/500\n",
      "858/858 [==============================] - 1s 919us/step - loss: 0.5590 - accuracy: 0.7250\n",
      "Epoch 258/500\n",
      "858/858 [==============================] - 1s 989us/step - loss: 0.5588 - accuracy: 0.7255\n",
      "Epoch 259/500\n",
      "858/858 [==============================] - 1s 878us/step - loss: 0.5589 - accuracy: 0.7260\n",
      "Epoch 260/500\n",
      "858/858 [==============================] - 1s 912us/step - loss: 0.5588 - accuracy: 0.7251\n",
      "Epoch 261/500\n",
      "858/858 [==============================] - 1s 906us/step - loss: 0.5588 - accuracy: 0.7263\n",
      "Epoch 262/500\n",
      "858/858 [==============================] - 1s 887us/step - loss: 0.5589 - accuracy: 0.7258\n",
      "Epoch 263/500\n",
      "858/858 [==============================] - 1s 911us/step - loss: 0.5589 - accuracy: 0.7256\n",
      "Epoch 264/500\n",
      "858/858 [==============================] - 1s 884us/step - loss: 0.5587 - accuracy: 0.7253\n",
      "Epoch 265/500\n",
      "858/858 [==============================] - 1s 947us/step - loss: 0.5590 - accuracy: 0.7254\n",
      "Epoch 266/500\n",
      "858/858 [==============================] - 1s 920us/step - loss: 0.5586 - accuracy: 0.7255\n",
      "Epoch 267/500\n",
      "858/858 [==============================] - 1s 900us/step - loss: 0.5587 - accuracy: 0.7255\n",
      "Epoch 268/500\n",
      "858/858 [==============================] - 1s 893us/step - loss: 0.5588 - accuracy: 0.7262\n",
      "Epoch 269/500\n",
      "858/858 [==============================] - 1s 910us/step - loss: 0.5589 - accuracy: 0.7261\n",
      "Epoch 270/500\n",
      "858/858 [==============================] - 1s 901us/step - loss: 0.5587 - accuracy: 0.7254\n",
      "Epoch 271/500\n",
      "858/858 [==============================] - 1s 895us/step - loss: 0.5589 - accuracy: 0.7258\n",
      "Epoch 272/500\n",
      "858/858 [==============================] - 1s 911us/step - loss: 0.5589 - accuracy: 0.7254\n",
      "Epoch 273/500\n",
      "858/858 [==============================] - 1s 969us/step - loss: 0.5588 - accuracy: 0.7248\n",
      "Epoch 274/500\n",
      "858/858 [==============================] - 1s 999us/step - loss: 0.5587 - accuracy: 0.7256\n",
      "Epoch 275/500\n",
      "858/858 [==============================] - 1s 877us/step - loss: 0.5587 - accuracy: 0.7259\n",
      "Epoch 276/500\n",
      "858/858 [==============================] - 1s 869us/step - loss: 0.5589 - accuracy: 0.7256\n",
      "Epoch 277/500\n",
      "858/858 [==============================] - 1s 890us/step - loss: 0.5588 - accuracy: 0.7252\n",
      "Epoch 278/500\n",
      "858/858 [==============================] - 1s 900us/step - loss: 0.5588 - accuracy: 0.7252\n",
      "Epoch 279/500\n",
      "858/858 [==============================] - 1s 918us/step - loss: 0.5586 - accuracy: 0.7257\n",
      "Epoch 280/500\n",
      "858/858 [==============================] - 1s 937us/step - loss: 0.5588 - accuracy: 0.7259\n",
      "Epoch 281/500\n",
      "858/858 [==============================] - 1s 904us/step - loss: 0.5587 - accuracy: 0.7263\n",
      "Epoch 282/500\n",
      "858/858 [==============================] - 1s 905us/step - loss: 0.5587 - accuracy: 0.7256\n",
      "Epoch 283/500\n",
      "858/858 [==============================] - 1s 915us/step - loss: 0.5587 - accuracy: 0.7260\n",
      "Epoch 284/500\n",
      "858/858 [==============================] - 1s 888us/step - loss: 0.5587 - accuracy: 0.7255\n",
      "Epoch 285/500\n",
      "858/858 [==============================] - 1s 932us/step - loss: 0.5587 - accuracy: 0.7256\n",
      "Epoch 286/500\n",
      "858/858 [==============================] - 1s 903us/step - loss: 0.5586 - accuracy: 0.7259\n",
      "Epoch 287/500\n",
      "858/858 [==============================] - 1s 918us/step - loss: 0.5586 - accuracy: 0.7254\n",
      "Epoch 288/500\n",
      "858/858 [==============================] - 1s 903us/step - loss: 0.5587 - accuracy: 0.7256\n",
      "Epoch 289/500\n",
      "858/858 [==============================] - 1s 914us/step - loss: 0.5587 - accuracy: 0.7254\n",
      "Epoch 290/500\n",
      "858/858 [==============================] - 1s 907us/step - loss: 0.5586 - accuracy: 0.7256\n",
      "Epoch 291/500\n",
      "858/858 [==============================] - 1s 922us/step - loss: 0.5586 - accuracy: 0.7256\n",
      "Epoch 292/500\n",
      "858/858 [==============================] - 1s 890us/step - loss: 0.5587 - accuracy: 0.7260\n",
      "Epoch 293/500\n",
      "858/858 [==============================] - 1s 903us/step - loss: 0.5587 - accuracy: 0.7258\n",
      "Epoch 294/500\n",
      "858/858 [==============================] - 1s 936us/step - loss: 0.5587 - accuracy: 0.7254\n",
      "Epoch 295/500\n",
      "858/858 [==============================] - 1s 891us/step - loss: 0.5586 - accuracy: 0.7253\n",
      "Epoch 296/500\n",
      "858/858 [==============================] - 1s 896us/step - loss: 0.5587 - accuracy: 0.7256\n",
      "Epoch 297/500\n",
      "858/858 [==============================] - 1s 909us/step - loss: 0.5586 - accuracy: 0.7256\n",
      "Epoch 298/500\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5586 - accuracy: 0.7252\n",
      "Epoch 299/500\n",
      "858/858 [==============================] - 1s 923us/step - loss: 0.5584 - accuracy: 0.7260\n",
      "Epoch 300/500\n",
      "858/858 [==============================] - 1s 894us/step - loss: 0.5587 - accuracy: 0.7256\n",
      "Epoch 301/500\n",
      "858/858 [==============================] - 1s 928us/step - loss: 0.5583 - accuracy: 0.7261\n",
      "Epoch 302/500\n",
      "858/858 [==============================] - 1s 902us/step - loss: 0.5584 - accuracy: 0.7261\n",
      "Epoch 303/500\n",
      "858/858 [==============================] - 1s 884us/step - loss: 0.5584 - accuracy: 0.7253\n",
      "Epoch 304/500\n",
      "858/858 [==============================] - 1s 918us/step - loss: 0.5584 - accuracy: 0.7251\n",
      "Epoch 305/500\n",
      "858/858 [==============================] - 1s 935us/step - loss: 0.5586 - accuracy: 0.7252\n",
      "Epoch 306/500\n",
      "858/858 [==============================] - 1s 903us/step - loss: 0.5585 - accuracy: 0.7259\n",
      "Epoch 307/500\n",
      "858/858 [==============================] - 1s 906us/step - loss: 0.5584 - accuracy: 0.7263\n",
      "Epoch 308/500\n",
      "858/858 [==============================] - 1s 926us/step - loss: 0.5585 - accuracy: 0.7257\n",
      "Epoch 309/500\n",
      "858/858 [==============================] - 1s 877us/step - loss: 0.5584 - accuracy: 0.7254\n",
      "Epoch 310/500\n",
      "858/858 [==============================] - 1s 912us/step - loss: 0.5586 - accuracy: 0.7255\n",
      "Epoch 311/500\n",
      "858/858 [==============================] - 1s 897us/step - loss: 0.5586 - accuracy: 0.7260\n",
      "Epoch 312/500\n",
      "858/858 [==============================] - 1s 927us/step - loss: 0.5584 - accuracy: 0.7262\n",
      "Epoch 313/500\n",
      "858/858 [==============================] - 1s 925us/step - loss: 0.5586 - accuracy: 0.7253\n",
      "Epoch 314/500\n",
      "858/858 [==============================] - 1s 895us/step - loss: 0.5586 - accuracy: 0.7260\n",
      "Epoch 315/500\n",
      "858/858 [==============================] - 1s 938us/step - loss: 0.5585 - accuracy: 0.7259\n",
      "Epoch 316/500\n",
      "858/858 [==============================] - 1s 910us/step - loss: 0.5584 - accuracy: 0.7258\n",
      "Epoch 317/500\n",
      "858/858 [==============================] - 1s 905us/step - loss: 0.5586 - accuracy: 0.7262\n",
      "Epoch 318/500\n",
      "858/858 [==============================] - 1s 921us/step - loss: 0.5586 - accuracy: 0.7254\n",
      "Epoch 319/500\n",
      "858/858 [==============================] - 1s 873us/step - loss: 0.5583 - accuracy: 0.7258\n",
      "Epoch 320/500\n",
      "858/858 [==============================] - 1s 905us/step - loss: 0.5586 - accuracy: 0.7265\n",
      "Epoch 321/500\n",
      "858/858 [==============================] - 1s 917us/step - loss: 0.5583 - accuracy: 0.7258\n",
      "Epoch 322/500\n",
      "858/858 [==============================] - 1s 923us/step - loss: 0.5584 - accuracy: 0.7258\n",
      "Epoch 323/500\n",
      "858/858 [==============================] - 1s 916us/step - loss: 0.5584 - accuracy: 0.7251\n",
      "Epoch 324/500\n",
      "858/858 [==============================] - 1s 895us/step - loss: 0.5585 - accuracy: 0.7262\n",
      "Epoch 325/500\n",
      "858/858 [==============================] - 1s 872us/step - loss: 0.5584 - accuracy: 0.7259\n",
      "Epoch 326/500\n",
      "858/858 [==============================] - 1s 909us/step - loss: 0.5585 - accuracy: 0.7259\n",
      "Epoch 327/500\n",
      "858/858 [==============================] - 1s 879us/step - loss: 0.5584 - accuracy: 0.7261\n",
      "Epoch 328/500\n",
      "858/858 [==============================] - 1s 933us/step - loss: 0.5584 - accuracy: 0.7253\n",
      "Epoch 329/500\n",
      "858/858 [==============================] - 1s 915us/step - loss: 0.5584 - accuracy: 0.7256\n",
      "Epoch 330/500\n",
      "858/858 [==============================] - 1s 897us/step - loss: 0.5584 - accuracy: 0.7259\n",
      "Epoch 331/500\n",
      "858/858 [==============================] - 1s 909us/step - loss: 0.5583 - accuracy: 0.7260\n",
      "Epoch 332/500\n",
      "858/858 [==============================] - 1s 901us/step - loss: 0.5584 - accuracy: 0.7258\n",
      "Epoch 333/500\n",
      "858/858 [==============================] - 1s 877us/step - loss: 0.5583 - accuracy: 0.7259\n",
      "Epoch 334/500\n",
      "858/858 [==============================] - 1s 928us/step - loss: 0.5582 - accuracy: 0.7263\n",
      "Epoch 335/500\n",
      "858/858 [==============================] - 1s 957us/step - loss: 0.5584 - accuracy: 0.7256\n",
      "Epoch 336/500\n",
      "858/858 [==============================] - 1s 909us/step - loss: 0.5584 - accuracy: 0.7254\n",
      "Epoch 337/500\n",
      "858/858 [==============================] - 1s 912us/step - loss: 0.5583 - accuracy: 0.7262\n",
      "Epoch 338/500\n",
      "858/858 [==============================] - 1s 901us/step - loss: 0.5581 - accuracy: 0.7260\n",
      "Epoch 339/500\n",
      "858/858 [==============================] - 1s 891us/step - loss: 0.5586 - accuracy: 0.7258\n",
      "Epoch 340/500\n",
      "858/858 [==============================] - 1s 957us/step - loss: 0.5584 - accuracy: 0.7261\n",
      "Epoch 341/500\n",
      "858/858 [==============================] - 1s 920us/step - loss: 0.5584 - accuracy: 0.7259\n",
      "Epoch 342/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5584 - accuracy: 0.7255\n",
      "Epoch 343/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5584 - accuracy: 0.7256\n",
      "Epoch 344/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5583 - accuracy: 0.7256\n",
      "Epoch 345/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5583 - accuracy: 0.7259\n",
      "Epoch 346/500\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5583 - accuracy: 0.7259\n",
      "Epoch 347/500\n",
      "858/858 [==============================] - 1s 996us/step - loss: 0.5582 - accuracy: 0.7262\n",
      "Epoch 348/500\n",
      "858/858 [==============================] - 1s 949us/step - loss: 0.5582 - accuracy: 0.7259\n",
      "Epoch 349/500\n",
      "858/858 [==============================] - 1s 907us/step - loss: 0.5582 - accuracy: 0.7260\n",
      "Epoch 350/500\n",
      "858/858 [==============================] - 1s 933us/step - loss: 0.5582 - accuracy: 0.7259\n",
      "Epoch 351/500\n",
      "858/858 [==============================] - 1s 930us/step - loss: 0.5582 - accuracy: 0.7260\n",
      "Epoch 352/500\n",
      "858/858 [==============================] - 1s 880us/step - loss: 0.5582 - accuracy: 0.7255\n",
      "Epoch 353/500\n",
      "858/858 [==============================] - 1s 915us/step - loss: 0.5584 - accuracy: 0.7262\n",
      "Epoch 354/500\n",
      "858/858 [==============================] - 1s 940us/step - loss: 0.5583 - accuracy: 0.7260\n",
      "Epoch 355/500\n",
      "858/858 [==============================] - 1s 890us/step - loss: 0.5583 - accuracy: 0.7264\n",
      "Epoch 356/500\n",
      "858/858 [==============================] - 1s 933us/step - loss: 0.5582 - accuracy: 0.7258\n",
      "Epoch 357/500\n",
      "858/858 [==============================] - 1s 914us/step - loss: 0.5582 - accuracy: 0.7255\n",
      "Epoch 358/500\n",
      "858/858 [==============================] - 1s 888us/step - loss: 0.5583 - accuracy: 0.7257\n",
      "Epoch 359/500\n",
      "858/858 [==============================] - 1s 910us/step - loss: 0.5581 - accuracy: 0.7263\n",
      "Epoch 360/500\n",
      "858/858 [==============================] - 1s 918us/step - loss: 0.5583 - accuracy: 0.7256\n",
      "Epoch 361/500\n",
      "858/858 [==============================] - 1s 917us/step - loss: 0.5581 - accuracy: 0.7257\n",
      "Epoch 362/500\n",
      "858/858 [==============================] - 1s 900us/step - loss: 0.5581 - accuracy: 0.7259\n",
      "Epoch 363/500\n",
      "858/858 [==============================] - 1s 904us/step - loss: 0.5582 - accuracy: 0.7264\n",
      "Epoch 364/500\n",
      "858/858 [==============================] - 1s 961us/step - loss: 0.5582 - accuracy: 0.7263\n",
      "Epoch 365/500\n",
      "858/858 [==============================] - 1s 927us/step - loss: 0.5580 - accuracy: 0.7259\n",
      "Epoch 366/500\n",
      "858/858 [==============================] - 1s 909us/step - loss: 0.5581 - accuracy: 0.7260\n",
      "Epoch 367/500\n",
      "858/858 [==============================] - 1s 936us/step - loss: 0.5582 - accuracy: 0.7255\n",
      "Epoch 368/500\n",
      "858/858 [==============================] - 1s 889us/step - loss: 0.5582 - accuracy: 0.7262\n",
      "Epoch 369/500\n",
      "858/858 [==============================] - 1s 903us/step - loss: 0.5581 - accuracy: 0.7262\n",
      "Epoch 370/500\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5581 - accuracy: 0.7257\n",
      "Epoch 371/500\n",
      "858/858 [==============================] - 1s 892us/step - loss: 0.5581 - accuracy: 0.7263\n",
      "Epoch 372/500\n",
      "858/858 [==============================] - 1s 971us/step - loss: 0.5581 - accuracy: 0.7260\n",
      "Epoch 373/500\n",
      "858/858 [==============================] - 1s 930us/step - loss: 0.5582 - accuracy: 0.7258\n",
      "Epoch 374/500\n",
      "858/858 [==============================] - 1s 894us/step - loss: 0.5580 - accuracy: 0.7262\n",
      "Epoch 375/500\n",
      "858/858 [==============================] - 1s 907us/step - loss: 0.5581 - accuracy: 0.7250\n",
      "Epoch 376/500\n",
      "858/858 [==============================] - 1s 911us/step - loss: 0.5581 - accuracy: 0.7260\n",
      "Epoch 377/500\n",
      "858/858 [==============================] - 1s 890us/step - loss: 0.5580 - accuracy: 0.7258\n",
      "Epoch 378/500\n",
      "858/858 [==============================] - 1s 940us/step - loss: 0.5581 - accuracy: 0.7260\n",
      "Epoch 379/500\n",
      "858/858 [==============================] - 1s 908us/step - loss: 0.5581 - accuracy: 0.7256\n",
      "Epoch 380/500\n",
      "858/858 [==============================] - 1s 926us/step - loss: 0.5580 - accuracy: 0.7262\n",
      "Epoch 381/500\n",
      "858/858 [==============================] - 1s 893us/step - loss: 0.5580 - accuracy: 0.7263\n",
      "Epoch 382/500\n",
      "858/858 [==============================] - 1s 902us/step - loss: 0.5581 - accuracy: 0.7261\n",
      "Epoch 383/500\n",
      "858/858 [==============================] - 1s 905us/step - loss: 0.5580 - accuracy: 0.7259\n",
      "Epoch 384/500\n",
      "858/858 [==============================] - 1s 925us/step - loss: 0.5581 - accuracy: 0.7256\n",
      "Epoch 385/500\n",
      "858/858 [==============================] - 1s 885us/step - loss: 0.5581 - accuracy: 0.7265\n",
      "Epoch 386/500\n",
      "858/858 [==============================] - 1s 927us/step - loss: 0.5580 - accuracy: 0.7258\n",
      "Epoch 387/500\n",
      "858/858 [==============================] - 1s 895us/step - loss: 0.5581 - accuracy: 0.7259\n",
      "Epoch 388/500\n",
      "858/858 [==============================] - 1s 920us/step - loss: 0.5580 - accuracy: 0.7262\n",
      "Epoch 389/500\n",
      "858/858 [==============================] - 1s 933us/step - loss: 0.5580 - accuracy: 0.7253\n",
      "Epoch 390/500\n",
      "858/858 [==============================] - 1s 933us/step - loss: 0.5581 - accuracy: 0.7255\n",
      "Epoch 391/500\n",
      "858/858 [==============================] - 1s 881us/step - loss: 0.5580 - accuracy: 0.7264\n",
      "Epoch 392/500\n",
      "858/858 [==============================] - 1s 911us/step - loss: 0.5580 - accuracy: 0.7264\n",
      "Epoch 393/500\n",
      "858/858 [==============================] - 1s 868us/step - loss: 0.5583 - accuracy: 0.7260\n",
      "Epoch 394/500\n",
      "858/858 [==============================] - 1s 914us/step - loss: 0.5579 - accuracy: 0.7260\n",
      "Epoch 395/500\n",
      "858/858 [==============================] - 1s 943us/step - loss: 0.5578 - accuracy: 0.7262\n",
      "Epoch 396/500\n",
      "858/858 [==============================] - 1s 907us/step - loss: 0.5580 - accuracy: 0.7259\n",
      "Epoch 397/500\n",
      "858/858 [==============================] - 1s 903us/step - loss: 0.5580 - accuracy: 0.7255\n",
      "Epoch 398/500\n",
      "858/858 [==============================] - 1s 895us/step - loss: 0.5580 - accuracy: 0.7262\n",
      "Epoch 399/500\n",
      "858/858 [==============================] - 1s 900us/step - loss: 0.5580 - accuracy: 0.7265\n",
      "Epoch 400/500\n",
      "858/858 [==============================] - 1s 942us/step - loss: 0.5581 - accuracy: 0.7256\n",
      "Epoch 401/500\n",
      "858/858 [==============================] - 1s 907us/step - loss: 0.5580 - accuracy: 0.7265\n",
      "Epoch 402/500\n",
      "858/858 [==============================] - 1s 918us/step - loss: 0.5580 - accuracy: 0.7256\n",
      "Epoch 403/500\n",
      "858/858 [==============================] - 1s 906us/step - loss: 0.5579 - accuracy: 0.7260\n",
      "Epoch 404/500\n",
      "858/858 [==============================] - 1s 910us/step - loss: 0.5579 - accuracy: 0.7258\n",
      "Epoch 405/500\n",
      "858/858 [==============================] - 1s 897us/step - loss: 0.5580 - accuracy: 0.7262\n",
      "Epoch 406/500\n",
      "858/858 [==============================] - 1s 938us/step - loss: 0.5580 - accuracy: 0.7262\n",
      "Epoch 407/500\n",
      "858/858 [==============================] - 1s 919us/step - loss: 0.5580 - accuracy: 0.7265\n",
      "Epoch 408/500\n",
      "858/858 [==============================] - 1s 996us/step - loss: 0.5579 - accuracy: 0.7254\n",
      "Epoch 409/500\n",
      "858/858 [==============================] - 1s 904us/step - loss: 0.5580 - accuracy: 0.7258\n",
      "Epoch 410/500\n",
      "858/858 [==============================] - 1s 906us/step - loss: 0.5580 - accuracy: 0.7258\n",
      "Epoch 411/500\n",
      "858/858 [==============================] - 1s 951us/step - loss: 0.5580 - accuracy: 0.7252\n",
      "Epoch 412/500\n",
      "858/858 [==============================] - 1s 902us/step - loss: 0.5580 - accuracy: 0.7257\n",
      "Epoch 413/500\n",
      "858/858 [==============================] - 1s 914us/step - loss: 0.5579 - accuracy: 0.7262\n",
      "Epoch 414/500\n",
      "858/858 [==============================] - 1s 923us/step - loss: 0.5578 - accuracy: 0.7269\n",
      "Epoch 415/500\n",
      "858/858 [==============================] - 1s 914us/step - loss: 0.5578 - accuracy: 0.7256\n",
      "Epoch 416/500\n",
      "858/858 [==============================] - 1s 908us/step - loss: 0.5579 - accuracy: 0.7268\n",
      "Epoch 417/500\n",
      "858/858 [==============================] - 1s 937us/step - loss: 0.5580 - accuracy: 0.7260\n",
      "Epoch 418/500\n",
      "858/858 [==============================] - 1s 899us/step - loss: 0.5579 - accuracy: 0.7263\n",
      "Epoch 419/500\n",
      "858/858 [==============================] - 1s 892us/step - loss: 0.5578 - accuracy: 0.7260\n",
      "Epoch 420/500\n",
      "858/858 [==============================] - 1s 926us/step - loss: 0.5579 - accuracy: 0.7258\n",
      "Epoch 421/500\n",
      "858/858 [==============================] - 1s 914us/step - loss: 0.5578 - accuracy: 0.7256\n",
      "Epoch 422/500\n",
      "858/858 [==============================] - 1s 947us/step - loss: 0.5580 - accuracy: 0.7259\n",
      "Epoch 423/500\n",
      "858/858 [==============================] - 1s 882us/step - loss: 0.5578 - accuracy: 0.7258\n",
      "Epoch 424/500\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5578 - accuracy: 0.7254\n",
      "Epoch 425/500\n",
      "858/858 [==============================] - 1s 901us/step - loss: 0.5579 - accuracy: 0.7259\n",
      "Epoch 426/500\n",
      "858/858 [==============================] - 1s 876us/step - loss: 0.5579 - accuracy: 0.7263\n",
      "Epoch 427/500\n",
      "858/858 [==============================] - 1s 927us/step - loss: 0.5581 - accuracy: 0.7257\n",
      "Epoch 428/500\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5579 - accuracy: 0.7263\n",
      "Epoch 429/500\n",
      "858/858 [==============================] - 2s 2ms/step - loss: 0.5579 - accuracy: 0.7267\n",
      "Epoch 430/500\n",
      "858/858 [==============================] - 1s 2ms/step - loss: 0.5579 - accuracy: 0.7260\n",
      "Epoch 431/500\n",
      "858/858 [==============================] - 1s 940us/step - loss: 0.5576 - accuracy: 0.7260\n",
      "Epoch 432/500\n",
      "858/858 [==============================] - 1s 874us/step - loss: 0.5577 - accuracy: 0.7259\n",
      "Epoch 433/500\n",
      "858/858 [==============================] - 1s 922us/step - loss: 0.5577 - accuracy: 0.7262\n",
      "Epoch 434/500\n",
      "858/858 [==============================] - 1s 905us/step - loss: 0.5578 - accuracy: 0.7261\n",
      "Epoch 435/500\n",
      "858/858 [==============================] - 1s 958us/step - loss: 0.5579 - accuracy: 0.7262\n",
      "Epoch 436/500\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5579 - accuracy: 0.7255\n",
      "Epoch 437/500\n",
      "858/858 [==============================] - 1s 956us/step - loss: 0.5578 - accuracy: 0.7266\n",
      "Epoch 438/500\n",
      "858/858 [==============================] - 1s 911us/step - loss: 0.5578 - accuracy: 0.7254\n",
      "Epoch 439/500\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5579 - accuracy: 0.7262\n",
      "Epoch 440/500\n",
      "858/858 [==============================] - 1s 893us/step - loss: 0.5578 - accuracy: 0.7264\n",
      "Epoch 441/500\n",
      "858/858 [==============================] - 1s 967us/step - loss: 0.5578 - accuracy: 0.7266\n",
      "Epoch 442/500\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5579 - accuracy: 0.7256\n",
      "Epoch 443/500\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5577 - accuracy: 0.7264\n",
      "Epoch 444/500\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5577 - accuracy: 0.7267\n",
      "Epoch 445/500\n",
      "858/858 [==============================] - 1s 956us/step - loss: 0.5578 - accuracy: 0.7261\n",
      "Epoch 446/500\n",
      "858/858 [==============================] - 1s 918us/step - loss: 0.5578 - accuracy: 0.7260\n",
      "Epoch 447/500\n",
      "858/858 [==============================] - 1s 897us/step - loss: 0.5577 - accuracy: 0.7261\n",
      "Epoch 448/500\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5577 - accuracy: 0.7262\n",
      "Epoch 449/500\n",
      "858/858 [==============================] - 1s 963us/step - loss: 0.5578 - accuracy: 0.7261\n",
      "Epoch 450/500\n",
      "858/858 [==============================] - 1s 973us/step - loss: 0.5577 - accuracy: 0.7255\n",
      "Epoch 451/500\n",
      "858/858 [==============================] - 1s 968us/step - loss: 0.5576 - accuracy: 0.7255\n",
      "Epoch 452/500\n",
      "858/858 [==============================] - 1s 899us/step - loss: 0.5579 - accuracy: 0.7261\n",
      "Epoch 453/500\n",
      "858/858 [==============================] - 1s 976us/step - loss: 0.5576 - accuracy: 0.7261\n",
      "Epoch 454/500\n",
      "858/858 [==============================] - 1s 898us/step - loss: 0.5577 - accuracy: 0.7258\n",
      "Epoch 455/500\n",
      "858/858 [==============================] - 1s 883us/step - loss: 0.5577 - accuracy: 0.7260\n",
      "Epoch 456/500\n",
      "858/858 [==============================] - 1s 905us/step - loss: 0.5577 - accuracy: 0.7260\n",
      "Epoch 457/500\n",
      "858/858 [==============================] - 1s 992us/step - loss: 0.5579 - accuracy: 0.7255\n",
      "Epoch 458/500\n",
      "858/858 [==============================] - 1s 865us/step - loss: 0.5577 - accuracy: 0.7264\n",
      "Epoch 459/500\n",
      "858/858 [==============================] - 1s 870us/step - loss: 0.5576 - accuracy: 0.7259\n",
      "Epoch 460/500\n",
      "858/858 [==============================] - 1s 891us/step - loss: 0.5578 - accuracy: 0.7262\n",
      "Epoch 461/500\n",
      "858/858 [==============================] - 1s 900us/step - loss: 0.5578 - accuracy: 0.7262\n",
      "Epoch 462/500\n",
      "858/858 [==============================] - 1s 934us/step - loss: 0.5578 - accuracy: 0.7262\n",
      "Epoch 463/500\n",
      "858/858 [==============================] - 1s 913us/step - loss: 0.5577 - accuracy: 0.7260\n",
      "Epoch 464/500\n",
      "858/858 [==============================] - 1s 928us/step - loss: 0.5575 - accuracy: 0.7260\n",
      "Epoch 465/500\n",
      "858/858 [==============================] - 1s 899us/step - loss: 0.5577 - accuracy: 0.7251\n",
      "Epoch 466/500\n",
      "858/858 [==============================] - 1s 906us/step - loss: 0.5578 - accuracy: 0.7259\n",
      "Epoch 467/500\n",
      "858/858 [==============================] - 1s 902us/step - loss: 0.5577 - accuracy: 0.7261\n",
      "Epoch 468/500\n",
      "858/858 [==============================] - 1s 924us/step - loss: 0.5576 - accuracy: 0.7262\n",
      "Epoch 469/500\n",
      "858/858 [==============================] - 1s 891us/step - loss: 0.5577 - accuracy: 0.7261\n",
      "Epoch 470/500\n",
      "858/858 [==============================] - 1s 903us/step - loss: 0.5577 - accuracy: 0.7257\n",
      "Epoch 471/500\n",
      "858/858 [==============================] - 1s 897us/step - loss: 0.5577 - accuracy: 0.7260\n",
      "Epoch 472/500\n",
      "858/858 [==============================] - 1s 915us/step - loss: 0.5577 - accuracy: 0.7262\n",
      "Epoch 473/500\n",
      "858/858 [==============================] - 1s 899us/step - loss: 0.5575 - accuracy: 0.7261\n",
      "Epoch 474/500\n",
      "858/858 [==============================] - 1s 902us/step - loss: 0.5575 - accuracy: 0.7264\n",
      "Epoch 475/500\n",
      "858/858 [==============================] - 1s 879us/step - loss: 0.5577 - accuracy: 0.7259\n",
      "Epoch 476/500\n",
      "858/858 [==============================] - 1s 901us/step - loss: 0.5576 - accuracy: 0.7260\n",
      "Epoch 477/500\n",
      "858/858 [==============================] - 1s 891us/step - loss: 0.5576 - accuracy: 0.7261\n",
      "Epoch 478/500\n",
      "858/858 [==============================] - 1s 927us/step - loss: 0.5578 - accuracy: 0.7262\n",
      "Epoch 479/500\n",
      "858/858 [==============================] - 1s 882us/step - loss: 0.5576 - accuracy: 0.7267\n",
      "Epoch 480/500\n",
      "858/858 [==============================] - 1s 900us/step - loss: 0.5577 - accuracy: 0.7264\n",
      "Epoch 481/500\n",
      "858/858 [==============================] - 1s 1ms/step - loss: 0.5576 - accuracy: 0.7258\n",
      "Epoch 482/500\n",
      "858/858 [==============================] - 1s 898us/step - loss: 0.5574 - accuracy: 0.7262\n",
      "Epoch 483/500\n",
      "858/858 [==============================] - 1s 892us/step - loss: 0.5575 - accuracy: 0.7257\n",
      "Epoch 484/500\n",
      "858/858 [==============================] - 1s 891us/step - loss: 0.5576 - accuracy: 0.7262\n",
      "Epoch 485/500\n",
      "858/858 [==============================] - 1s 892us/step - loss: 0.5574 - accuracy: 0.7264\n",
      "Epoch 486/500\n",
      "858/858 [==============================] - 1s 912us/step - loss: 0.5575 - accuracy: 0.7259\n",
      "Epoch 487/500\n",
      "858/858 [==============================] - 1s 889us/step - loss: 0.5575 - accuracy: 0.7255\n",
      "Epoch 488/500\n",
      "858/858 [==============================] - 1s 892us/step - loss: 0.5574 - accuracy: 0.7264\n",
      "Epoch 489/500\n",
      "858/858 [==============================] - 1s 929us/step - loss: 0.5577 - accuracy: 0.7259\n",
      "Epoch 490/500\n",
      "858/858 [==============================] - 1s 905us/step - loss: 0.5576 - accuracy: 0.7258\n",
      "Epoch 491/500\n",
      "858/858 [==============================] - 1s 891us/step - loss: 0.5576 - accuracy: 0.7268\n",
      "Epoch 492/500\n",
      "858/858 [==============================] - 1s 900us/step - loss: 0.5575 - accuracy: 0.7255\n",
      "Epoch 493/500\n",
      "858/858 [==============================] - 1s 920us/step - loss: 0.5576 - accuracy: 0.7260\n",
      "Epoch 494/500\n",
      "858/858 [==============================] - 1s 869us/step - loss: 0.5575 - accuracy: 0.7262\n",
      "Epoch 495/500\n",
      "858/858 [==============================] - 1s 893us/step - loss: 0.5576 - accuracy: 0.7262\n",
      "Epoch 496/500\n",
      "858/858 [==============================] - 1s 951us/step - loss: 0.5575 - accuracy: 0.7259\n",
      "Epoch 497/500\n",
      "858/858 [==============================] - 1s 889us/step - loss: 0.5575 - accuracy: 0.7265\n",
      "Epoch 498/500\n",
      "858/858 [==============================] - 1s 965us/step - loss: 0.5574 - accuracy: 0.7262\n",
      "Epoch 499/500\n",
      "858/858 [==============================] - 1s 897us/step - loss: 0.5576 - accuracy: 0.7265\n",
      "Epoch 500/500\n",
      "858/858 [==============================] - 1s 896us/step - loss: 0.5574 - accuracy: 0.7263\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model = nn3.fit(X_train_scaled_3, y_train_3, epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 0s 662us/step - loss: 0.5647 - accuracy: 0.7261\n",
      "Loss: 0.5646992325782776, Accuracy: 0.7260932922363281\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn3.evaluate(X_test_scaled_3,y_test_3,verbose=1)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69d0a6f26c6cc950e691e199a5b79e52a310d6b21ddbe60098d61ecb2a00e61d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
